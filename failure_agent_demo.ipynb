{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d586f25",
   "metadata": {},
   "source": [
    "# Agent: Failure Prediction\n",
    "\n",
    "AI-Driven Predictive Maintenance with MongoDB Atlas\n",
    "\n",
    "Overview\n",
    "This notebook demonstrates an agentic workflow for failure prediction and root cause analysis in industrial settings, leveraging MongoDB Atlas as the central data platform.\n",
    "\n",
    "Automated Root Cause Analysis\n",
    "\n",
    "The end user sends an equipment malfunction alert to the agent\n",
    "Failure Agent performs diagnostics that traditionally take hours manually\n",
    "Atlas Vector Search retrieves contextual insights from:\n",
    "Historical maintenance logs\n",
    "Equipment documentation\n",
    "Environmental data (temperature, humidity, etc.)\n",
    "ERP/MES systems\n",
    "LLM analyzes gathered context and generates incident reports with corrective actions\n",
    "\n",
    "Architecture Flow\n",
    "Real-time Alerts → AI Agents → Root Cause Analysis → Incident Reports\n",
    "\n",
    "## Prerequisites\n",
    "- MongoDB Atlas cluster with Atlas Vector Search enabled\n",
    "- Voyage AI API key\n",
    "- OpenAI API key\n",
    "- Python packages: pymongo, voyageai, openai, langchain, langchain-openai, langgraph, asyncio, nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb3ef7",
   "metadata": {},
   "source": [
    "## 1: Import Required Libraries and Configure Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2963f1f3",
   "metadata": {},
   "source": [
    "## Setup: Configure Virtual Environment and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a0d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in ./.venv/lib/python3.13/site-packages (0.9.9)\n",
      "Requirement already satisfied: pymongo in ./.venv/lib/python3.13/site-packages (4.16.0)\n",
      "Requirement already satisfied: voyageai in ./.venv/lib/python3.13/site-packages (0.3.7)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.13/site-packages (2.15.0)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.13/site-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.13/site-packages (1.1.7)\n",
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.13/site-packages (1.0.7)\n",
      "Requirement already satisfied: asyncio in ./.venv/lib/python3.13/site-packages (4.0.0)\n",
      "Requirement already satisfied: nest_asyncio in ./.venv/lib/python3.13/site-packages (1.6.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (from dotenv) (1.2.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=2.6.1 in ./.venv/lib/python3.13/site-packages (from pymongo) (2.8.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.13/site-packages (from voyageai) (3.13.3)\n",
      "Requirement already satisfied: aiolimiter in ./.venv/lib/python3.13/site-packages (from voyageai) (1.2.1)\n",
      "Requirement already satisfied: ffmpeg-python in ./.venv/lib/python3.13/site-packages (from voyageai) (0.2.0)\n",
      "Requirement already satisfied: langchain-text-splitters>=0.3.8 in ./.venv/lib/python3.13/site-packages (from voyageai) (1.1.0)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./.venv/lib/python3.13/site-packages (from voyageai) (2.4.1)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from voyageai) (12.1.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in ./.venv/lib/python3.13/site-packages (from voyageai) (2.12.5)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from voyageai) (2.32.5)\n",
      "Requirement already satisfied: tenacity in ./.venv/lib/python3.13/site-packages (from voyageai) (9.1.2)\n",
      "Requirement already satisfied: tokenizers>=0.14.0 in ./.venv/lib/python3.13/site-packages (from voyageai) (0.22.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.13/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (0.4.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in ./.venv/lib/python3.13/site-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in ./.venv/lib/python3.13/site-packages (from langgraph) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.6.6)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./.venv/lib/python3.13/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.13/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (0.25.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->voyageai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->voyageai) (2.6.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./.venv/lib/python3.13/site-packages (from tokenizers>=0.14.0->voyageai) (1.3.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (1.2.0)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (0.21.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.22.0)\n",
      "Requirement already satisfied: future in ./.venv/lib/python3.13/site-packages (from ffmpeg-python->voyageai) (1.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing a libraries' directly in the notebook\n",
    "%pip install dotenv pymongo voyageai openai langchain langchain-openai langgraph asyncio nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95be3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Status:\n",
      "✓ MongoDB URI configured: True\n",
      "✓ Voyage AI API key configured: True\n",
      "✓ Voyage AI Embedding model configured: True\n",
      "✓ OpenAI API key configured: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ServerSelectionTimeoutError\n",
    "from pymongo.operations import SearchIndexModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import voyageai\n",
    "#import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure MONGODB URI from environment variables\n",
    "MONGODB_URI = os.getenv(\"MONGODB_URI\")\n",
    "DATABASE_NAME = os.getenv(\"DATABASE_NAME\")\n",
    "\n",
    "# Configure LLM endpoint and API keys from environment variables\n",
    "LLM_API_ENDPOINT = os.getenv(\"LLM_API_ENDPOINT\")\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\")\n",
    "\n",
    "# Change the base URL\n",
    "VOYAGE_API_ENDPOINT = os.getenv(\"VOYAGE_API_ENDPOINT\")\n",
    "VOYAGE_API_KEY = os.getenv(\"VOYAGE_API_KEY\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")\n",
    "\n",
    "# Validate that API keys are available\n",
    "print(\"Configuration Status:\")\n",
    "print(f\"✓ MongoDB URI configured: {bool(MONGODB_URI)}\")\n",
    "print(f\"✓ Voyage AI API key configured: {bool(VOYAGE_API_KEY)}\")\n",
    "print(f\"✓ Voyage AI Embedding model configured: {bool(EMBEDDING_MODEL)}\")\n",
    "print(f\"✓ OpenAI API key configured: {bool(LLM_API_KEY)}\")\n",
    "\n",
    "# Initialize API clients\n",
    "if VOYAGE_API_KEY:\n",
    "    #voyageai.base_url = VOYAGE_API_ENDPOINT\n",
    "    voyage_client = voyageai.Client(api_key=VOYAGE_API_KEY)\n",
    "    \n",
    "if LLM_API_KEY:\n",
    "    #openai.base_url = LLM_API_ENDPOINT\n",
    "    llm_client = OpenAI( api_key=LLM_API_KEY )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978da6f",
   "metadata": {},
   "source": [
    "## 2: Connect to MongoDB Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c83011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully connected to MongoDB Atlas\n",
      "✓ Database: pmd\n",
      "✓ Available collections: ['interviews', 'workorders', 'manuals', 'incident_reports']\n"
     ]
    }
   ],
   "source": [
    "def connect_to_mongodb(uri: str, db_name: str = DATABASE_NAME) -> tuple:\n",
    "    \"\"\"\n",
    "    Connect to MongoDB Atlas cluster\n",
    "    \n",
    "    Args:\n",
    "        uri: MongoDB connection string\n",
    "        db_name: Database name to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (client, database)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "        # Verify connection\n",
    "        client.admin.command('ping')\n",
    "        db = client[db_name]\n",
    "        print(f\"✓ Successfully connected to MongoDB Atlas\")\n",
    "        print(f\"✓ Database: {db_name}\")\n",
    "        return client, db\n",
    "    except ServerSelectionTimeoutError:\n",
    "        print(\"✗ Failed to connect to MongoDB Atlas. Check your connection string.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Connection error: {e}\")\n",
    "        raise\n",
    "\n",
    "# Connect to MongoDB\n",
    "if MONGODB_URI:\n",
    "    mongo_client, db = connect_to_mongodb(MONGODB_URI)\n",
    "    print(f\"✓ Available collections: {db.list_collection_names()}\")\n",
    "else:\n",
    "    print(\"✗ MONGODB_URI not configured. Please set the environment variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd92e9",
   "metadata": {},
   "source": [
    "## 3: Load and Ingest Datasets from Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8fb025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading datasets from: /Users/mancilla/sw/demo-rag-pm/data\n",
      "Available files: [PosixPath('data/manuals.json'), PosixPath('data/workorders.json'), PosixPath('data/maintenance_staff.json'), PosixPath('data/interviews.json'), PosixPath('data/inventory.json')]\n",
      "\n",
      "✓ Loaded data/manuals.json: 6 documents\n",
      "✓ Loaded data/interviews.json: 5 documents\n",
      "✓ Loaded data/workorders.json: 10 documents\n",
      "\n",
      "Dataset Summary:\n",
      "  - Manuals: 6 documents\n",
      "  - Interviews: 5 documents\n",
      "  - Work Orders: 10 documents\n"
     ]
    }
   ],
   "source": [
    "def load_json_dataset(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load a JSON dataset from file\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file\n",
    "        \n",
    "    Returns:\n",
    "        List of documents\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"✓ Loaded {file_path}: {len(data)} documents\")\n",
    "        return data if isinstance(data, list) else [data]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"✗ File not found: {file_path}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"✗ Error decoding JSON from {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Locate the data folder\n",
    "data_folder = Path(\"./data\")\n",
    "if not data_folder.exists():\n",
    "    print(f\"✗ Data folder not found at {data_folder.absolute()}\")\n",
    "    # Try alternative path\n",
    "    alt_path = Path(\"../data\")\n",
    "    if alt_path.exists():\n",
    "        data_folder = alt_path\n",
    "    else:\n",
    "        print(\"Please ensure the data folder exists in the workspace root\")\n",
    "\n",
    "print(f\"\\nLoading datasets from: {data_folder.absolute()}\")\n",
    "print(f\"Available files: {list(data_folder.glob('*'))}\\n\")\n",
    "\n",
    "# Load datasets\n",
    "manuals_data = load_json_dataset(str(data_folder / \"manuals.json\"))\n",
    "interviews_data = load_json_dataset(str(data_folder / \"interviews.json\"))\n",
    "workorders_data = load_json_dataset(str(data_folder / \"workorders.json\"))\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  - Manuals: {len(manuals_data)} documents\")\n",
    "print(f\"  - Interviews: {len(interviews_data)} documents\")\n",
    "print(f\"  - Work Orders: {len(workorders_data)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b15bb686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ingested 6 documents into 'manuals'\n",
      "✓ Ingested 5 documents into 'interviews'\n",
      "✓ Ingested 10 documents into 'workorders'\n",
      "\n",
      "✓ Data ingestion complete\n"
     ]
    }
   ],
   "source": [
    "def ingest_data_to_mongodb(db, collection_name: str, documents: List[Dict]) -> bool:\n",
    "    \"\"\"\n",
    "    Ingest documents into a MongoDB collection\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        collection_name: Name of the collection\n",
    "        documents: List of documents to insert\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        print(f\"✗ No documents to ingest into {collection_name}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        collection = db[collection_name]\n",
    "        # Drop existing collection to start fresh\n",
    "        collection.drop()\n",
    "        \n",
    "        # Insert documents\n",
    "        result = collection.insert_many(documents)\n",
    "        print(f\"✓ Ingested {len(result.inserted_ids)} documents into '{collection_name}'\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error ingesting data into {collection_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Ingest datasets into MongoDB\n",
    "if MONGODB_URI and manuals_data:\n",
    "    ingest_data_to_mongodb(db, \"manuals\", manuals_data)\n",
    "    \n",
    "if MONGODB_URI and interviews_data:\n",
    "    ingest_data_to_mongodb(db, \"interviews\", interviews_data)\n",
    "\n",
    "if MONGODB_URI and workorders_data:\n",
    "    ingest_data_to_mongodb(db, \"workorders\", workorders_data)\n",
    "\n",
    "print(\"\\n✓ Data ingestion complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d4fb2",
   "metadata": {},
   "source": [
    "## 4: Generate Embeddings Using Voyage AI 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8209481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Voyage AI embedding generation...\n",
      "✓ Generated 2 embeddings using voyage-3-large\n",
      "✓ Sample embedding dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "def extract_text_for_embedding(document: Dict[str, Any], text_fields: List[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Extract text content from a document for embedding\n",
    "    \n",
    "    Args:\n",
    "        document: The document to extract text from\n",
    "        text_fields: List of field names to extract (if None, uses sensible defaults)\n",
    "        \n",
    "    Returns:\n",
    "        Combined text string\n",
    "    \"\"\"\n",
    "    if text_fields is None:\n",
    "        # Default fields to check for text content\n",
    "        text_fields = ['text', 'title', 'observations']\n",
    "    \n",
    "    texts = []\n",
    "    for field in text_fields:\n",
    "        if field in document and document[field]:\n",
    "            value = document[field]\n",
    "            if isinstance(value, str):\n",
    "                texts.append(value)\n",
    "            elif isinstance(value, list):\n",
    "                texts.extend([str(v) for v in value if v])\n",
    "    \n",
    "    return \" \".join(texts)\n",
    "\n",
    "def generate_embeddings_batch(texts: List[str], model: str = EMBEDDING_MODEL) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Generate embeddings for a batch of texts using Voyage AI\n",
    "    \n",
    "    Args:\n",
    "        texts: List of texts to embed\n",
    "        model: Voyage AI model to use\n",
    "        \n",
    "    Returns:\n",
    "        List of embedding vectors\n",
    "    \"\"\"\n",
    "    if not texts:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Create embeddings using Voyage AI\n",
    "        response = voyage_client.embed(\n",
    "            texts=texts,\n",
    "            model=model,\n",
    "            input_type=\"document\"\n",
    "        )\n",
    "        embeddings = [e for e in response.embeddings]\n",
    "        print(f\"✓ Generated {len(embeddings)} embeddings using {model}\")\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error generating embeddings: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test embedding generation with a sample\n",
    "print(\"Testing Voyage AI embedding generation...\")\n",
    "test_texts = [\"This is a test document\", \"Another test text for embeddings\"]\n",
    "test_embeddings = generate_embeddings_batch(test_texts)\n",
    "if test_embeddings:\n",
    "    print(f\"✓ Sample embedding dimension: {len(test_embeddings[0])}\")\n",
    "else:\n",
    "    print(\"✗ Embedding generation failed. Check API key and connectivity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2b54e",
   "metadata": {},
   "source": [
    "## 5: Update Collections with Embeddings Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1292c9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GENERATING AND ADDING EMBEDDINGS TO COLLECTIONS\n",
      "============================================================\n",
      "\n",
      "Processing 6 documents in 'manuals'...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGENERATING AND ADDING EMBEDDINGS TO COLLECTIONS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43madd_embeddings_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmanuals\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m add_embeddings_to_collection(db, \u001b[33m\"\u001b[39m\u001b[33minterviews\u001b[39m\u001b[33m\"\u001b[39m, batch_size=\u001b[32m5\u001b[39m)\n\u001b[32m     63\u001b[39m add_embeddings_to_collection(db, \u001b[33m\"\u001b[39m\u001b[33mworkorders\u001b[39m\u001b[33m\"\u001b[39m, batch_size=\u001b[32m10\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36madd_embeddings_to_collection\u001b[39m\u001b[34m(db, collection_name, batch_size)\u001b[39m\n\u001b[32m     28\u001b[39m texts = [extract_text_for_embedding(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Generate embeddings for the batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m embeddings = \u001b[43mgenerate_embeddings_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m embeddings \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(embeddings) != \u001b[38;5;28mlen\u001b[39m(batch):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✗ Embedding generation failed for batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi//batch_size\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mgenerate_embeddings_batch\u001b[39m\u001b[34m(texts, model)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# Create embeddings using Voyage AI\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     response = \u001b[43mvoyage_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocument\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     embeddings = [e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m response.embeddings]\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Generated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(embeddings)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m embeddings using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/voyageai/client.py:76\u001b[39m, in \u001b[36mClient.embed\u001b[39m\u001b[34m(self, texts, model, input_type, truncation, output_dtype, output_dimension)\u001b[39m\n\u001b[32m     68\u001b[39m     warnings.warn(\n\u001b[32m     69\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe `model` argument is not specified and defaults to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvoyageai.VOYAGE_EMBED_DEFAULT_MODEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt will be a required argument in the future. We recommend to specify the model when using this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfunction. Please see https://docs.voyageai.com/docs/embeddings for the list of latest models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprovided by Voyage AI.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m     )\n\u001b[32m     75\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_retry_controller\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoyageai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/tenacity/__init__.py:445\u001b[39m, in \u001b[36mBaseRetrying.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    443\u001b[39m retry_state = RetryCallState(\u001b[38;5;28mself\u001b[39m, fn=\u001b[38;5;28;01mNone\u001b[39;00m, args=(), kwargs={})\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    447\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m AttemptManager(retry_state=retry_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/voyageai/client.py:78\u001b[39m, in \u001b[36mClient.embed\u001b[39m\u001b[34m(self, texts, model, input_type, truncation, output_dtype, output_dimension)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_retry_controller():\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m attempt:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         response = \u001b[43mvoyageai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_dimension\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error.APIConnectionError(\u001b[33m\"\u001b[39m\u001b[33mFailed to get response after all retry attempts\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/voyageai/api_resources/embedding.py:19\u001b[39m, in \u001b[36mEmbedding.create\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_provided_encoding_format:\n\u001b[32m     17\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoding_format\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mbase64\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# This is only for the default case.\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_provided_encoding_format:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/voyageai/api_resources/api_resource.py:45\u001b[39m, in \u001b[36mAPIResource.create\u001b[39m\u001b[34m(cls, api_key, request_id, request_timeout, **params)\u001b[39m\n\u001b[32m     42\u001b[39m base_url = params.pop(\u001b[33m\"\u001b[39m\u001b[33mbase_url\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     43\u001b[39m requestor, url, params, headers = \u001b[38;5;28mcls\u001b[39m.__prepare_create_request(api_key, base_url, **params)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m response = \u001b[43mrequestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m obj = convert_to_voyage_response(response)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/voyageai/api_resources/api_requestor.py:136\u001b[39m, in \u001b[36mAPIRequestor.request\u001b[39m\u001b[34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    127\u001b[39m     method,\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    135\u001b[39m ) -> VoyageHttpResponse:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._interpret_response(result)\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/voyageai/api_resources/api_requestor.py:306\u001b[39m, in \u001b[36mAPIRequestor.request_raw\u001b[39m\u001b[34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[39m\n\u001b[32m    304\u001b[39m     _thread_context.session_create_time = time.time()\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     result = \u001b[43m_thread_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_thread_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.Timeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error.Timeout(\u001b[33m\"\u001b[39m\u001b[33mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/urllib3/connection.py:571\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    568\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    574\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1450\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1449\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1450\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1451\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1452\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:336\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    338\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:297\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    299\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def add_embeddings_to_collection(db, collection_name: str, batch_size: int = 10) -> bool:\n",
    "    \"\"\"\n",
    "    Generate embeddings for all documents in a collection and update them\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        collection_name: Name of the collection to process\n",
    "        batch_size: Number of documents to process per batch\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        collection = db[collection_name]\n",
    "        documents = list(collection.find({}))\n",
    "        \n",
    "        if not documents:\n",
    "            print(f\"✗ No documents found in collection '{collection_name}'\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"\\nProcessing {len(documents)} documents in '{collection_name}'...\")\n",
    "        \n",
    "        # Process documents in batches\n",
    "        for i in range(0, len(documents), batch_size):\n",
    "            batch = documents[i:i + batch_size]\n",
    "            \n",
    "            # Extract text from documents\n",
    "            texts = [extract_text_for_embedding(doc) for doc in batch]\n",
    "            \n",
    "            # Generate embeddings for the batch\n",
    "            embeddings = generate_embeddings_batch(texts)\n",
    "            \n",
    "            if not embeddings or len(embeddings) != len(batch):\n",
    "                print(f\"✗ Embedding generation failed for batch {i//batch_size + 1}\")\n",
    "                continue\n",
    "            \n",
    "            # Update documents with embeddings\n",
    "            for doc, embedding in zip(batch, embeddings):\n",
    "                collection.update_one(\n",
    "                    {\"_id\": doc[\"_id\"]},\n",
    "                    {\"$set\": {\"embeddings\": embedding}}\n",
    "                )\n",
    "            \n",
    "            print(f\"  ✓ Processed batch {i//batch_size + 1}/{(len(documents) + batch_size - 1)//batch_size}\")\n",
    "        \n",
    "        # Verify embeddings were added\n",
    "        docs_with_embeddings = collection.count_documents({\"embeddings\": {\"$exists\": True}})\n",
    "        print(f\"✓ Updated {docs_with_embeddings} documents with embeddings in '{collection_name}'\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error adding embeddings to {collection_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Add embeddings to both collections\n",
    "if MONGODB_URI and test_embeddings:  # Only proceed if embeddings work\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GENERATING AND ADDING EMBEDDINGS TO COLLECTIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    add_embeddings_to_collection(db, \"manuals\", batch_size=5)\n",
    "    add_embeddings_to_collection(db, \"interviews\", batch_size=5)\n",
    "    add_embeddings_to_collection(db, \"workorders\", batch_size=10)\n",
    "else:\n",
    "    print(\"✗ Skipping embedding generation - API not configured or failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4025258",
   "metadata": {},
   "source": [
    "## 6: Create Vector Indexes in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cea92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING VECTOR SEARCH INDEXES\n",
      "============================================================\n",
      "✓ Created vector search index for 'manuals'\n",
      "✓ Created vector search index for 'interviews'\n",
      "✓ Created vector search index for 'workorders'\n"
     ]
    }
   ],
   "source": [
    "def create_vector_search_index(db, collection_name: str, embedding_dim: int = 1024) -> bool:\n",
    "    \"\"\"\n",
    "    Create a vector search index on the embeddings field\n",
    "    \n",
    "    Note: This requires MongoDB Atlas with Atlas Vector Search enabled\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        collection_name: Name of the collection\n",
    "        embedding_dim: Dimension of the embeddings\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        collection = db[collection_name]\n",
    "        \n",
    "        # Vector search index definition for Atlas Vector Search\n",
    "\n",
    "\n",
    "        search_index_model = SearchIndexModel(\n",
    "                                    definition={\n",
    "                                        \"fields\": [\n",
    "                                        {\n",
    "                                            \"type\": \"vector\",\n",
    "                                            \"path\": \"embeddings\",\n",
    "                                            \"numDimensions\": embedding_dim,\n",
    "                                            \"similarity\": \"cosine\"\n",
    "                                        }\n",
    "                                        ]\n",
    "                                    },\n",
    "                                    name=\"vector_index\",\n",
    "                                    type=\"vectorSearch\"\n",
    "                                )\n",
    "\n",
    "\n",
    "        \n",
    "        # Create the index via the collection's create_search_indexes method\n",
    "        # Note: This method requires MongoDB Python driver >= 4.6\n",
    "        try:\n",
    "            # Try using the newer search indexes API\n",
    "            search_indexes = collection.list_search_indexes()\n",
    "            existing_indexes = [idx.get('name') for idx in search_indexes]\n",
    "            for index in existing_indexes:\n",
    "                print(index)\n",
    "            \n",
    "            if 'vector_index' not in existing_indexes:\n",
    "                collection.create_search_index(model=search_index_model)\n",
    "                print(f\"✓ Created vector search index for '{collection_name}'\")\n",
    "            else:\n",
    "                print(f\"✓ Vector search index already exists for '{collection_name}'\")\n",
    "                \n",
    "        except AttributeError:\n",
    "            # Fallback for older driver versions\n",
    "            print(f\"⚠ Vector search index creation requires MongoDB Atlas with Vector Search enabled\")\n",
    "            print(f\"  Manually create the index in MongoDB Atlas UI with this definition:\")\n",
    "            print(f\"  {json.dumps(index_definition, indent=2)}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Note: {e}\")\n",
    "        print(f\"  Vector indexes should be created in MongoDB Atlas UI\")\n",
    "        return False\n",
    "\n",
    "# Create vector indexes for both collections\n",
    "if MONGODB_URI and test_embeddings:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CREATING VECTOR SEARCH INDEXES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Use embedding dimension from test\n",
    "    embedding_dim = len(test_embeddings[0]) if test_embeddings else 1024\n",
    "    \n",
    "    create_vector_search_index(db, \"manuals\", embedding_dim)\n",
    "    create_vector_search_index(db, \"interviews\", embedding_dim)\n",
    "    create_vector_search_index(db, \"workorders\", embedding_dim)\n",
    "else:\n",
    "    print(\"✗ Skipping index creation - prerequisites not met\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8e2cf",
   "metadata": {},
   "source": [
    "## 7: Implement RAG Solution with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAG system initialized successfully\n"
     ]
    }
   ],
   "source": [
    "def vector_search_mongodb(db, collection_name: str, query: str, num_results: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform vector similarity search on MongoDB collection\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        collection_name: Name of the collection to search\n",
    "        query: Query in natural language\n",
    "        num_results: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of matching documents with similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        collection = db[collection_name]\n",
    "\n",
    "        query_embedding = generate_embeddings_batch([query])\n",
    "        query_vector = query_embedding[0]\n",
    "\n",
    "        \n",
    "        # Use aggregation pipeline with vector search\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$vectorSearch\": {\n",
    "                    \"index\": \"vector_index\",\n",
    "                    'queryVector': query_vector,\n",
    "                    'numCandidates': 10, \n",
    "                    'limit': num_results\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"'score\": {\"$meta\": \"vectorSearchScore\"},\n",
    "                    \"document\": \"$$ROOT\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$limit\": num_results\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Try standard vector search first\n",
    "        try:\n",
    "            results = list(collection.aggregate(pipeline))\n",
    "            return results\n",
    "        except:\n",
    "            # Fallback to simpler approach if aggregation fails\n",
    "            # This works with documents that have embeddings field\n",
    "            results = []\n",
    "            documents = list(collection.find({\"embeddings\": {\"$exists\": True}}))\n",
    "            \n",
    "            if not documents:\n",
    "                return []\n",
    "            \n",
    "            # Calculate similarity scores using cosine similarity\n",
    "            import numpy as np\n",
    "            query_vec = np.array(query_vector)\n",
    "            \n",
    "            for doc in documents:\n",
    "                if 'embeddings' in doc:\n",
    "                    doc_vec = np.array(doc['embeddings'])\n",
    "                    # Cosine similarity\n",
    "                    similarity = np.dot(query_vec, doc_vec) / (np.linalg.norm(query_vec) * np.linalg.norm(doc_vec))\n",
    "                    results.append({\n",
    "                        'similarityScore': float(similarity),\n",
    "                        'document': doc\n",
    "                    })\n",
    "            \n",
    "            # Sort by similarity score and return top results\n",
    "            results.sort(key=lambda x: x['similarityScore'], reverse=True)\n",
    "            return results[:num_results]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error performing vector search: {e}\")\n",
    "        return []\n",
    "\n",
    "def retrieve_context(db, query: str, num_results: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant context from both collections using vector search\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        query: User query\n",
    "        num_results: Number of results per collection\n",
    "        \n",
    "    Returns:\n",
    "        Formatted context string for RAG\n",
    "    \"\"\"\n",
    "    # Generate query embedding\n",
    "    \n",
    "    if not query:\n",
    "        return \"No context available\"\n",
    "        \n",
    "    # Search both collections\n",
    "    manual_results = vector_search_mongodb(db, \"manuals\", query, num_results)\n",
    "    interview_results = vector_search_mongodb(db, \"interviews\", query, num_results)\n",
    "    workorder_results = vector_search_mongodb(db, \"workorders\", query, num_results)\n",
    "\n",
    "    # Format context\n",
    "    context = \"Retrieved Context:\\n\\n\"\n",
    "    \n",
    "    if manual_results:\n",
    "        context += \"=== From Manuals ===\\n\"\n",
    "        for i, result in enumerate(manual_results, 1):\n",
    "            doc = result.get('document', result)\n",
    "            score = result.get('similarityScore', 0)\n",
    "            text = extract_text_for_embedding(doc)[:500]  # Limit text length\n",
    "            context += f\"{i}. (Score: {score:.2f}) {text}...\\n\\n\"\n",
    "    \n",
    "    if interview_results:\n",
    "        context += \"=== From Interviews ===\\n\"\n",
    "        for i, result in enumerate(interview_results, 1):\n",
    "            doc = result.get('document', result)\n",
    "            score = result.get('similarityScore', 0)\n",
    "            text = extract_text_for_embedding(doc)[:500]  # Limit text length\n",
    "            context += f\"{i}. (Score: {score:.2f}) {text}...\\n\\n\"\n",
    "\n",
    "    if workorder_results:\n",
    "        context += \"=== From Work Orders ===\\n\"\n",
    "        for i, result in enumerate(workorder_results, 1):\n",
    "            doc = result.get('document', result)\n",
    "            score = result.get('similarityScore', 0)\n",
    "            text = extract_text_for_embedding(doc)[:500]  # Limit text length\n",
    "            context += f\"{i}. (Score: {score:.2f}) {text}...\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "# Initialize RAG system\n",
    "class MongoDBOpenAIRAG:\n",
    "    \"\"\"RAG system using MongoDB Atlas and OpenAI\"\"\"\n",
    "    \n",
    "    def __init__(self, db, model: str = \"gpt-3.5-turbo\", temperature: float = 0.7):\n",
    "        self.db = db\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def answer_question(self, query: str, num_context_docs: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Answer a question using RAG approach\n",
    "        \n",
    "        Args:\n",
    "            query: User question\n",
    "            num_context_docs: Number of context documents to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            Dict with answer, context, and sources\n",
    "        \"\"\"\n",
    "        # Retrieve context\n",
    "        context = retrieve_context(self.db, query, num_context_docs)\n",
    "        \n",
    "        # Create prompt for OpenAI\n",
    "        system_prompt = \"\"\"You are a helpful assistant answering questions about maintenance systems and procedures.\n",
    "Use the provided context to answer the question accurately. If the context doesn't contain relevant information, say so.\n",
    "Always cite your sources from the context.\"\"\"\n",
    "        \n",
    "        user_message = f\"\"\"Context Information:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Please provide a helpful answer based on the context above.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Call OpenAI API\n",
    "            response = llm_client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_message}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=500\n",
    "            )\n",
    "\n",
    "            answer = response.choices[0].message.content\n",
    "\n",
    "            return {\n",
    "                'success': True,\n",
    "                'query': query,\n",
    "                'answer': answer,\n",
    "                'context': context,\n",
    "                'model': self.model\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'query': query,\n",
    "                'error': str(e),\n",
    "                'context': context\n",
    "            }\n",
    "\n",
    "# Initialize RAG system\n",
    "if MONGODB_URI and LLM_API_KEY:\n",
    "    rag_system = MongoDBOpenAIRAG(db)\n",
    "    print(\"✓ RAG system initialized successfully\")\n",
    "else:\n",
    "    print(\"✗ RAG system initialization failed - missing API keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73cfa0",
   "metadata": {},
   "source": [
    "## 8: Query and Retrieve Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RAG SYSTEM DEMONSTRATION\n",
      "======================================================================\n",
      "\n",
      "Running example queries...\n",
      "\n",
      "\n",
      "--- Query 1 ---\n",
      "✓ Generated 1 embeddings using voyage-3-large\n",
      "✓ Generated 1 embeddings using voyage-3-large\n",
      "✓ Generated 1 embeddings using voyage-3-large\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, query \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(example_queries, \u001b[32m1\u001b[39m):\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Query \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     response = \u001b[43mrag_system\u001b[49m\u001b[43m.\u001b[49m\u001b[43manswer_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_context_docs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     formatted = format_rag_response(response)\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mprint\u001b[39m(formatted)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 165\u001b[39m, in \u001b[36mMongoDBOpenAIRAG.answer_question\u001b[39m\u001b[34m(self, query, num_context_docs)\u001b[39m\n\u001b[32m    156\u001b[39m         user_message = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mContext Information:\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    158\u001b[39m \n\u001b[32m    159\u001b[39m \u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    160\u001b[39m \n\u001b[32m    161\u001b[39m \u001b[33mPlease provide a helpful answer based on the context above.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    164\u001b[39m             \u001b[38;5;66;03m# Call OpenAI API\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m             response = \u001b[43mllm_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_message\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m             answer = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m    177\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    178\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    179\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m'\u001b[39m: query,\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mself\u001b[39m.model\n\u001b[32m    183\u001b[39m             }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/demo-rag-pm/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def format_rag_response(response: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Format RAG response for display\n",
    "    \n",
    "    Args:\n",
    "        response: Response dictionary from RAG system\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string for display\n",
    "    \"\"\"\n",
    "    output = \"\\n\" + \"=\" * 70 + \"\\n\"\n",
    "    output += f\"QUERY: {response.get('query', 'N/A')}\\n\"\n",
    "    output += \"=\" * 70 + \"\\n\\n\"\n",
    "    \n",
    "    if response.get('success'):\n",
    "        output += f\"ANSWER:\\n{response.get('answer', 'No answer generated')}\\n\\n\"\n",
    "        output += \"-\" * 70 + \"\\n\"\n",
    "        output += f\"CONTEXT SOURCES:\\n{response.get('context', 'No context retrieved')}\\n\"\n",
    "    else:\n",
    "        output += f\"ERROR: {response.get('error', 'Unknown error')}\\n\"\n",
    "        output += f\"RETRIEVED CONTEXT:\\n{response.get('context', 'No context')}\\n\"\n",
    "    \n",
    "    output += \"=\" * 70 + \"\\n\"\n",
    "    return output\n",
    "\n",
    "# Example queries to test the RAG system\n",
    "example_queries = [\n",
    "    \"What are the maintenance procedures for critical equipment?\",\n",
    "    \"E12 high temperature\",\n",
    "    \"What is the recommended maintenance schedule?\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RAG SYSTEM DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'rag_system' in locals() and MONGODB_URI:\n",
    "    print(\"\\nRunning example queries...\\n\")\n",
    "    \n",
    "    for i, query in enumerate(example_queries, 1):\n",
    "        print(f\"\\n--- Query {i} ---\")\n",
    "        response = rag_system.answer_question(query, num_context_docs=2)\n",
    "        formatted = format_rag_response(response)\n",
    "        print(formatted)\n",
    "        \n",
    "        # Add a small delay between API calls to avoid rate limiting\n",
    "        import time\n",
    "        if i < len(example_queries):\n",
    "            time.sleep(2)\n",
    "else:\n",
    "    print(\"\\n✗ RAG system not available for querying\")\n",
    "    print(\"  Ensure MONGODB_URI and OPENAI_API_KEY are configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b62c0f",
   "metadata": {},
   "source": [
    "## 9. Import Required Libraries\n",
    "\n",
    "Import necessary libraries including langchain, langgraph, and other dependencies for building the failure agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c552f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, Optional, List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain and LangGraph imports\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import StateSnapshot\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d3d3c",
   "metadata": {},
   "source": [
    "## 10. Define the State Schema\n",
    "\n",
    "The state schema maintains the conversation history and messages throughout the agent's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ State schema defined\n"
     ]
    }
   ],
   "source": [
    "# Define State Schema\n",
    "from typing import TypedDict\n",
    "\n",
    "class FailureAgentState(TypedDict):\n",
    "    \"\"\"State schema for the Failure Agent\"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    \n",
    "print(\"✓ State schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c4374c",
   "metadata": {},
   "source": [
    "## 11. Create Tool Functions\n",
    "\n",
    "The failure agent uses four main tools to diagnose failures and generate incident reports:\n",
    "- **retrieve_manual**: Search technical manuals for relevant information\n",
    "- **retrieve_work_orders**: Find related maintenance work orders\n",
    "- **retrieve_interviews**: Access maintenance staff expertise and historical insights\n",
    "- **generate_incident_report**: Create and store incident reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d6d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tool functions defined and registered (using MongoDB + Voyage AI)\n",
      "✓ Language model configured with tools\n",
      "✓ Tool test result:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"incident_id\": \"697ab8459d85f13c7659a41d\",\n",
      "  \"message\": \"Incident report created successfully\",\n",
      "  \"error_code\": \"E12\",\n",
      "  \"machine_id\": \"M1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== IMPROVED TOOL DEFINITIONS =====\n",
    "\n",
    "def insert_incident_report(\n",
    "    error_code: str,\n",
    "    error_name: str,\n",
    "    root_cause: str,\n",
    "    repair_instructions: List[Dict[str, Any]],\n",
    "    machine_id: str,\n",
    "    timestamp: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Insert an incident report into MongoDB.\n",
    "    \n",
    "    Args:\n",
    "        error_code: The error code\n",
    "        error_name: Human-readable error name\n",
    "        root_cause: Root cause analysis\n",
    "        repair_instructions: List of repair steps with step and description keys\n",
    "        machine_id: Machine ID\n",
    "        timestamp: Optional timestamp\n",
    "        \n",
    "    Returns:\n",
    "        Dict with success status and incident ID\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timezone\n",
    "    \n",
    "    try:\n",
    "        # Validate repair instructions\n",
    "        if not isinstance(repair_instructions, list) or len(repair_instructions) == 0:\n",
    "            raise ValueError(\"repair_instructions must be a non-empty list\")\n",
    "        \n",
    "        # Ensure each instruction has required fields\n",
    "        validated_instructions = []\n",
    "        for i, instruction in enumerate(repair_instructions):\n",
    "            if isinstance(instruction, str):\n",
    "                validated_instructions.append({\"step\": i + 1, \"description\": instruction})\n",
    "            elif isinstance(instruction, dict):\n",
    "                if \"description\" not in instruction:\n",
    "                    instruction[\"description\"] = str(instruction)\n",
    "                if \"step\" not in instruction:\n",
    "                    instruction[\"step\"] = i + 1\n",
    "                validated_instructions.append(instruction)\n",
    "            else:\n",
    "                validated_instructions.append({\"step\": i + 1, \"description\": str(instruction)})\n",
    "        \n",
    "        collection = db[\"incident_reports\"]\n",
    "        \n",
    "        report = {\n",
    "            \"error_code\": error_code,\n",
    "            \"error_name\": error_name,\n",
    "            \"root_cause\": root_cause,\n",
    "            \"repair_instructions\": validated_instructions,\n",
    "            \"machine_id\": machine_id,\n",
    "            \"timestamp\": timestamp or datetime.now(timezone.utc).isoformat(),\n",
    "            \"status\": \"created\",\n",
    "            \"created_at\": datetime.now(timezone.utc).isoformat(),\n",
    "        }\n",
    "        \n",
    "        result = collection.insert_one(report)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"incident_id\": str(result.inserted_id),\n",
    "            \"message\": \"Incident report created successfully\",\n",
    "            \"error_code\": error_code,\n",
    "            \"machine_id\": machine_id\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"message\": f\"Failed to insert incident report: {e}\"\n",
    "        }\n",
    "\n",
    "\n",
    "@tool\n",
    "def retrieve_manual(query: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant technical manuals for the alert via MongoDB vector search.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for technical documentation\n",
    "        n: Number of results to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing relevant manual excerpts\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = vector_search_mongodb(db, \"manuals\", query, n)\n",
    "        if not results:\n",
    "            return json.dumps({\"found\": False, \"message\": \"No manuals found for query\"})\n",
    "        \n",
    "        formatted_results = []\n",
    "        for result in results:\n",
    "            doc = result.get('document', result)\n",
    "            score = result.get('similarityScore', 0)\n",
    "            text = extract_text_for_embedding(doc)[:300]\n",
    "            formatted_results.append({\n",
    "                \"score\": round(score, 3),\n",
    "                \"content\": text\n",
    "            })\n",
    "        \n",
    "        return json.dumps({\"found\": True, \"count\": len(formatted_results), \"results\": formatted_results})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e), \"found\": False})\n",
    "\n",
    "\n",
    "@tool\n",
    "def retrieve_work_orders(query: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve related work orders for the alert via MongoDB vector search.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for work orders\n",
    "        n: Number of results to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing related work order information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = vector_search_mongodb(db, \"workorders\", query, n)\n",
    "        if not results:\n",
    "            return json.dumps({\"found\": False, \"message\": \"No work orders found for query\"})\n",
    "        \n",
    "        formatted_results = []\n",
    "        for result in results:\n",
    "            doc = result.get('document', result)\n",
    "            score = result.get('similarityScore', 0)\n",
    "            text = extract_text_for_embedding(doc)[:300]\n",
    "            formatted_results.append({\n",
    "                \"score\": round(score, 3),\n",
    "                \"content\": text\n",
    "            })\n",
    "        \n",
    "        return json.dumps({\"found\": True, \"count\": len(formatted_results), \"results\": formatted_results})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e), \"found\": False})\n",
    "\n",
    "\n",
    "@tool\n",
    "def retrieve_interviews(query: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve interviews and expertise related to the alert via MongoDB vector search.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for maintenance expertise\n",
    "        n: Number of results to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing relevant interview excerpts\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = vector_search_mongodb(db, \"interviews\", query, n)\n",
    "        if not results:\n",
    "            return json.dumps({\"found\": False, \"message\": \"No interviews found for query\"})\n",
    "        \n",
    "        formatted_results = []\n",
    "        for result in results:\n",
    "            doc = result.get('document', result)\n",
    "            score = result.get('similarityScore', 0)\n",
    "            text = extract_text_for_embedding(doc)[:300]\n",
    "            formatted_results.append({\n",
    "                \"score\": round(score, 3),\n",
    "                \"content\": text\n",
    "            })\n",
    "        \n",
    "        return json.dumps({\"found\": True, \"count\": len(formatted_results), \"results\": formatted_results})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e), \"found\": False})\n",
    "\n",
    "\n",
    "@tool\n",
    "def generate_incident_report(\n",
    "    error_code: str,\n",
    "    error_name: str,\n",
    "    root_cause: str,\n",
    "    repair_instructions: List[str],\n",
    "    machine_id: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate and store an incident report in MongoDB for the failure alert.\n",
    "    \n",
    "    Args:\n",
    "        error_code: The error code for the incident (e.g., \"E12\")\n",
    "        error_name: Human-readable name of the error (e.g., \"High temperature\")\n",
    "        root_cause: Root cause analysis inferred from context (detailed explanation)\n",
    "        repair_instructions: List of repair step descriptions as strings (e.g., [\"Step 1: Stop the motor\", \"Step 2: Inspect bearing\"])\n",
    "        machine_id: ID of the affected machine\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with incident report confirmation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert string list to dict list with step numbers\n",
    "        instructions_with_steps = []\n",
    "        for i, instruction in enumerate(repair_instructions, 1):\n",
    "            instructions_with_steps.append({\n",
    "                \"step\": i,\n",
    "                \"description\": str(instruction)\n",
    "            })\n",
    "        \n",
    "        result = insert_incident_report(\n",
    "            error_code=error_code,\n",
    "            error_name=error_name,\n",
    "            root_cause=root_cause,\n",
    "            repair_instructions=instructions_with_steps,\n",
    "            machine_id=machine_id\n",
    "        )\n",
    "        return json.dumps(result)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"message\": f\"Error creating incident report: {e}\"\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "# Get all tools\n",
    "tools = [retrieve_manual, retrieve_work_orders, retrieve_interviews, generate_incident_report]\n",
    "\n",
    "print(\"✓ Tool functions defined and registered (using MongoDB + Voyage AI)\")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"COMPLETION_MODEL\"),\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"LLM_API_KEY\")\n",
    ")\n",
    "\n",
    "# Bind tools to the model\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"✓ Language model configured with tools\")\n",
    "\n",
    "# Test the generate_incident_report tool directly\n",
    "test_report = insert_incident_report(\n",
    "    error_code=\"E12\",\n",
    "    error_name=\"High temperature\",\n",
    "    root_cause=\"Bearing friction due to insufficient lubrication\",\n",
    "    repair_instructions=[\n",
    "        {\"step\": 1, \"description\": \"Stop the motor and let it cool\"},\n",
    "        {\"step\": 2, \"description\": \"Inspect bearing for damage\"},\n",
    "        {\"step\": 3, \"description\": \"Apply fresh lubricant\"},\n",
    "        {\"step\": 4, \"description\": \"Restart and monitor temperature\"}\n",
    "    ],\n",
    "    machine_id=\"M1\"\n",
    ")\n",
    "\n",
    "print(\"✓ Tool test result:\")\n",
    "print(json.dumps(test_report, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ffdcb",
   "metadata": {},
   "source": [
    "12. Define Agent Nodes and Routing Logic\n",
    "Agent Node\n",
    "The agent node processes incoming messages and calls the LLM to determine the next action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e9a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agent node defined\n"
     ]
    }
   ],
   "source": [
    "# Define the Agent Node\n",
    "async def agent_node(state: FailureAgentState) -> FailureAgentState:\n",
    "    \"\"\"\n",
    "    The agent node:\n",
    "    1. Receives alert details about machine failures\n",
    "    2. Routes to appropriate tools for information gathering\n",
    "    3. Analyzes retrieved context\n",
    "    4. Decides when to generate incident report\n",
    "    \"\"\"\n",
    "    # Create the prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are the Failure Agent. Your role is to:\n",
    "1. Receive alert details about machine failures\n",
    "2. Retrieve additional context from manuals, work orders, and maintenance expertise\n",
    "3. Analyze the root cause of the failure\n",
    "4. Generate a comprehensive incident report with repair instructions\n",
    "\n",
    "IMPORTANT: When calling generate_incident_report, you MUST provide:\n",
    "- error_code: The error code from the alert\n",
    "- error_name: The error name from the alert\n",
    "- root_cause: Your analysis of why this failure occurred based on retrieved context\n",
    "- repair_instructions: A LIST OF STRINGS describing step-by-step repair procedures (required - never omit!)\n",
    "- machine_id: The machine ID from the alert\n",
    "\n",
    "Example repair_instructions format:\n",
    "[\"Stop the motor and allow it to cool for 30 minutes\", \"Inspect the bearing for wear and damage\", \"Apply fresh lubricant to bearings\", \"Restart motor and monitor temperature\"]\n",
    "\n",
    "Use your tools strategically to gather all necessary information before generating the incident report.\n",
    "After the incident report is generated, acknowledge the completion with a brief summary.\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ])\n",
    "    \n",
    "    # Format the messages\n",
    "    formatted_prompt = await prompt.ainvoke({\"messages\": state[\"messages\"]})\n",
    "    \n",
    "    # Get the response from the model\n",
    "    response = await llm_with_tools.ainvoke(formatted_prompt)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }\n",
    "\n",
    "print(\"✓ Agent node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c8bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tool execution node defined\n"
     ]
    }
   ],
   "source": [
    "# Define the Tool Execution Node\n",
    "async def process_tool_calls(state: FailureAgentState) -> FailureAgentState:\n",
    "    \"\"\"\n",
    "    Process tool calls from the agent and return the results.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    tool_results = []\n",
    "    \n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_input = tool_call[\"args\"]\n",
    "            \n",
    "            print(f\"\\n🔧 Executing tool: {tool_name}\")\n",
    "            print(f\"   Input: {tool_input}\")\n",
    "            \n",
    "            # Find and execute the tool\n",
    "            for tool in tools:\n",
    "                if tool.name == tool_name:\n",
    "                    result = await tool.ainvoke(tool_input)\n",
    "                    print(f\"   Result: {result[:100]}...\")\n",
    "                    \n",
    "                    tool_message = ToolMessage(\n",
    "                        content=result,\n",
    "                        tool_call_id=tool_call[\"id\"]\n",
    "                    )\n",
    "                    tool_results.append(tool_message)\n",
    "                    break\n",
    "    \n",
    "    return {\n",
    "        \"messages\": tool_results\n",
    "    }\n",
    "\n",
    "print(\"✓ Tool execution node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Routing logic defined\n"
     ]
    }
   ],
   "source": [
    "# Define the Routing Logic\n",
    "def should_continue(state: FailureAgentState) -> str:\n",
    "    \"\"\"\n",
    "    Routes to 'tools' node if tool calls present\n",
    "    Returns END otherwise to terminate agent loop\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the last message has tool calls, route to the tools node\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, end the agent\n",
    "    return END\n",
    "\n",
    "print(\"✓ Routing logic defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215cb00e",
   "metadata": {},
   "source": [
    "## 13. Compile the Graph\n",
    "\n",
    "Create the StateGraph and compile it into an executable agent.\n",
    "Creates a StateGraph with proper node connections:\n",
    "\n",
    "Graph Structure:\n",
    "START → agent → [decision]\n",
    "                    ├─→ tools → agent (loop back)\n",
    "                    └─→ END\n",
    "\n",
    "Compilation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Failure Agent graph compiled successfully\n"
     ]
    }
   ],
   "source": [
    "# Build the StateGraph\n",
    "workflow = StateGraph(FailureAgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", process_tool_calls)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "failure_agent = workflow.compile()\n",
    "\n",
    "print(\"✓ Failure Agent graph compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca24513",
   "metadata": {},
   "source": [
    "## 14. Test Scenario: Motor Overheating Alert (E12)\n",
    "Alert Input\n",
    "\n",
    "{\n",
    "  \"err_code\": \"E12\",\n",
    "  \"err_name\": \"High temperature\",\n",
    "  \"machine_id\": \"M1\",\n",
    "  \"details\": {\n",
    "    \"temperature\": 114.55,\n",
    "    \"vibration\": 0.235\n",
    "  },\n",
    "  \"ts\": \"2026-01-26T01:01:04.980Z\",\n",
    "  \"status\": \"new\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f96f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST SCENARIO 1: MOTOR OVERHEATING (E001)\n",
      "================================================================================\n",
      "\n",
      "📨 Input Alert:\n",
      "\n",
      "{ \"err_code\": \"E12\",  \n",
      "  \"err_name\": \"High temperature\",  \n",
      "  \"machine_id\": \"M1\",  \n",
      "  \"details\": {  \"temperature\": 114.55,    \n",
      "                \"vibration\": 0.235  },  \n",
      "                \"ts\": {    \"$date\": \"2026-01-26T01:01:04.980Z\"  },  \n",
      "  \"status\": \"new\"}\n",
      "\n",
      "\n",
      "🤖 Agent Processing...\n",
      "\n",
      "🔧 Executing tool: retrieve_manual\n",
      "   Input: {'query': 'high temperature machine M1'}\n",
      "✓ Generated 1 embeddings using voyage-3-large\n",
      "   Result: {\"found\": true, \"count\": 3, \"results\": [{\"score\": 0.661, \"content\": \"Operating Parameters:\\n- Operat...\n",
      "\n",
      "🔧 Executing tool: retrieve_work_orders\n",
      "   Input: {'query': 'machine M1 high temperature'}\n",
      "✓ Generated 1 embeddings using voyage-3-large\n",
      "   Result: {\"found\": true, \"count\": 3, \"results\": [{\"score\": 0.77, \"content\": \"High Temperature Fault \\u2013 To...\n",
      "\n",
      "🔧 Executing tool: retrieve_interviews\n",
      "   Input: {'query': 'high temperature machine M1'}\n",
      "✓ Generated 1 embeddings using voyage-3-large\n",
      "   Result: {\"found\": true, \"count\": 3, \"results\": [{\"score\": 0.685, \"content\": \"When you get a high temperature...\n",
      "\n",
      "🔧 Executing tool: generate_incident_report\n",
      "   Input: {'error_code': 'E12', 'error_name': 'High temperature', 'root_cause': 'The high temperature alert on machine M1 is likely caused by a combination of factors: tool wear leading to increased heat generation, intermittent coolant blockages affecting cooling efficiency, and potential bearing misalignment due to vibration. These issues have contributed to the temperature exceeding the normal operating range.', 'repair_instructions': ['Inspect cutting tool for wear and replace if necessary', 'Check coolant system for blockages and ensure proper flow', 'Verify lubrication system functionality and address any issues', 'Inspect bearings for misalignment and realign if needed'], 'machine_id': 'M1'}\n",
      "   Result: {\"success\": true, \"incident_id\": \"697ab84e9d85f13c7659a41e\", \"message\": \"Incident report created suc...\n",
      "\n",
      "✅ Agent Completed Processing.\n",
      "\n",
      "📋 Final State Messages:\n",
      "  - HumanMessage: \n",
      "{ \"err_code\": \"E12\",  \n",
      "  \"err_name\": \"High temperature\",  \n",
      "  \"machine_id\": \"M1\",  \n",
      "  \"details\": {  ...\n",
      "  - AIMessage: ...\n",
      "  - ToolMessage: {\"found\": true, \"count\": 3, \"results\": [{\"score\": 0.661, \"content\": \"Operating Parameters:\\n- Operat...\n",
      "  - AIMessage: ...\n",
      "  - ToolMessage: {\"found\": true, \"count\": 3, \"results\": [{\"score\": 0.77, \"content\": \"High Temperature Fault \\u2013 To...\n",
      "  - AIMessage: ...\n",
      "  - ToolMessage: {\"found\": true, \"count\": 3, \"results\": [{\"score\": 0.685, \"content\": \"When you get a high temperature...\n",
      "  - AIMessage: ...\n",
      "  - ToolMessage: {\"success\": true, \"incident_id\": \"697ab84e9d85f13c7659a41e\", \"message\": \"Incident report created suc...\n",
      "  - AIMessage: The incident report for the high temperature alert on machine M1 has been successfully generated. Th...\n",
      "\n",
      "✅ Agent Completed Processing.\n"
     ]
    }
   ],
   "source": [
    "# Test Scenario 1: Motor Overheating\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST SCENARIO 1: MOTOR OVERHEATING (E001)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_input_1 = \"\"\"\n",
    "{ \"err_code\": \"E12\",  \n",
    "  \"err_name\": \"High temperature\",  \n",
    "  \"machine_id\": \"M1\",  \n",
    "  \"details\": {  \"temperature\": 114.55,    \n",
    "                \"vibration\": 0.235  },  \n",
    "                \"ts\": {    \"$date\": \"2026-01-26T01:01:04.980Z\"  },  \n",
    "  \"status\": \"new\"}\n",
    "\"\"\"\n",
    "\n",
    "initial_state_1 = {\n",
    "    \"messages\": [HumanMessage(content=test_input_1)]\n",
    "}\n",
    "\n",
    "print(\"\\n📨 Input Alert:\")\n",
    "print(test_input_1)\n",
    "print(\"\\n🤖 Agent Processing...\")\n",
    "\n",
    "\n",
    "# Run the agent asynchronously\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the agent directly without wrapping\n",
    "result = asyncio.run(failure_agent.ainvoke(initial_state_1))\n",
    "\n",
    "\n",
    "print(\"\\n✅ Agent Completed Processing.\")\n",
    "print(\"\\n📋 Final State Messages:\")\n",
    "for msg in result.get(\"messages\", []):\n",
    "    print(f\"  - {type(msg).__name__}: {str(msg.content)[:100]}...\")\n",
    "\n",
    "print(\"\\n✅ Agent Completed Processing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
