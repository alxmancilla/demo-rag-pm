{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8204a989",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates a production-ready failure agent implementation using LangGraph. The agent:\n",
    "\n",
    "- **Receives** machine failure alerts with error codes and details\n",
    "- **Analyzes** the failure using multiple retrieval tools\n",
    "- **Synthesizes** information from technical documentation, maintenance history, and expert knowledge\n",
    "- **Generates** comprehensive incident reports with step-by-step repair instructions\n",
    "- **Maintains** conversation history for audit and learning purposes\n",
    "\n",
    "The LangGraph framework provides:\n",
    "- Clear workflow definition with nodes and edges\n",
    "- Automatic tool binding and execution\n",
    "- Message history management\n",
    "- Extensibility for adding new tools and decision logic\n",
    "- Support for async operations\n",
    "\n",
    "To use this in production:\n",
    "1. Replace mock databases with real MongoDB connections and vector embeddings\n",
    "2. Configure OpenAI API credentials\n",
    "3. Add persistent storage for incident reports\n",
    "4. Implement checkpointing for long-running operations\n",
    "5. Add error handling and retry logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5acd0c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AGENT GRAPH STRUCTURE:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Nodes:\n",
      "  - agent: Processes input and calls LLM with tool bindings\n",
      "  - tools: Executes tool calls and returns results\n",
      "\n",
      "Edges:\n",
      "  - START â†’ agent: Entry point\n",
      "  - agent â†’ tools: When agent calls tools\n",
      "  - tools â†’ agent: Loop back for next reasoning step\n",
      "  - agent â†’ END: When no more tool calls needed\n",
      "\n",
      "State Schema:\n",
      "  - messages: Annotated list of BaseMessage objects\n",
      "              (Maintains conversation history)\n",
      "\n",
      "Routing Logic:\n",
      "  - If last message has tool_calls â†’ route to \"tools\" node\n",
      "  - Otherwise â†’ route to END (terminate)\n",
      "\n",
      "Execution Flow:\n",
      "  1. User provides alert details via HumanMessage\n",
      "  2. Agent receives message and decides what tools to use\n",
      "  3. Agent calls appropriate retrieval and analysis tools\n",
      "  4. Tool results returned as ToolMessages\n",
      "  5. Agent synthesizes results and generates incident report\n",
      "  6. Agent generates final summary\n",
      "  7. Graph terminates with complete incident documentation\n",
      "\n",
      "\n",
      "USAGE EXAMPLE:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "# Input an alert\n",
      "initial_state = {\n",
      "    \"messages\": [\n",
      "        HumanMessage(content=\"Alert: Machine MACH-001 reported error E001 at 10:30 AM\")\n",
      "    ]\n",
      "}\n",
      "\n",
      "# Run the agent asynchronously\n",
      "import asyncio\n",
      "result = await failure_agent.ainvoke(initial_state)\n",
      "\n",
      "# Access the conversation history\n",
      "for message in result[\"messages\"]:\n",
      "    print(f\"{message.__class__.__name__}: {message.content}\")\n",
      "\n",
      "# Incidents are stored in INCIDENT_REPORTS for later retrieval\n",
      "print(f\"Total incidents created: {len(INCIDENT_REPORTS)}\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Graph structure information\n",
    "graph_info = f\"\"\"\n",
    "AGENT GRAPH STRUCTURE:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Nodes:\n",
    "  - agent: Processes input and calls LLM with tool bindings\n",
    "  - tools: Executes tool calls and returns results\n",
    "\n",
    "Edges:\n",
    "  - START â†’ agent: Entry point\n",
    "  - agent â†’ tools: When agent calls tools\n",
    "  - tools â†’ agent: Loop back for next reasoning step\n",
    "  - agent â†’ END: When no more tool calls needed\n",
    "\n",
    "State Schema:\n",
    "  - messages: Annotated list of BaseMessage objects\n",
    "              (Maintains conversation history)\n",
    "\n",
    "Routing Logic:\n",
    "  - If last message has tool_calls â†’ route to \"tools\" node\n",
    "  - Otherwise â†’ route to END (terminate)\n",
    "\n",
    "Execution Flow:\n",
    "  1. User provides alert details via HumanMessage\n",
    "  2. Agent receives message and decides what tools to use\n",
    "  3. Agent calls appropriate retrieval and analysis tools\n",
    "  4. Tool results returned as ToolMessages\n",
    "  5. Agent synthesizes results and generates incident report\n",
    "  6. Agent generates final summary\n",
    "  7. Graph terminates with complete incident documentation\n",
    "\"\"\"\n",
    "\n",
    "print(graph_info)\n",
    "\n",
    "# Show how to use the agent\n",
    "usage_example = \"\"\"\n",
    "USAGE EXAMPLE:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Input an alert\n",
    "initial_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"Alert: Machine MACH-001 reported error E001 at 10:30 AM\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Run the agent asynchronously\n",
    "import asyncio\n",
    "result = await failure_agent.ainvoke(initial_state)\n",
    "\n",
    "# Access the conversation history\n",
    "for message in result[\"messages\"]:\n",
    "    print(f\"{message.__class__.__name__}: {message.content}\")\n",
    "\n",
    "# Incidents are stored in INCIDENT_REPORTS for later retrieval\n",
    "print(f\"Total incidents created: {len(INCIDENT_REPORTS)}\")\n",
    "\"\"\"\n",
    "\n",
    "print(usage_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcc1b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚                     FAILURE AGENT WORKFLOW                       â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "                              START\n",
      "                                â”‚\n",
      "                                â–¼\n",
      "                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "                        â”‚    AGENT     â”‚\n",
      "                        â”‚  Node: Call  â”‚\n",
      "                        â”‚ Language LLM â”‚\n",
      "                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                                â”‚\n",
      "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "                    â”‚                       â”‚\n",
      "              Tool Calls?              No Calls\n",
      "                    â”‚                       â”‚\n",
      "                    â–¼                       â–¼\n",
      "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "            â”‚    TOOLS     â”‚         â”‚   AGENT SENDS   â”‚\n",
      "            â”‚ Node: Processâ”‚         â”‚   FINAL MESSAGE â”‚\n",
      "            â”‚ Tool Results â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
      "                    â”‚                        â–¼\n",
      "                    â”‚                       END\n",
      "                    â”‚\n",
      "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                            â–²\n",
      "                            â”‚\n",
      "        Continue loop while agent has tool calls\n",
      "\n",
      "\n",
      "TOOLS AVAILABLE TO THE AGENT:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "1. retrieve_manual(query, n=3)\n",
      "   - Searches technical documentation\n",
      "   - Returns relevant manuals and procedures\n",
      "   - Helps understand error codes and prevention\n",
      "\n",
      "2. retrieve_work_orders(query, n=3)\n",
      "   - Finds related maintenance history\n",
      "   - Shows previous occurrences and resolutions\n",
      "   - Provides proven repair strategies\n",
      "\n",
      "3. retrieve_interviews(query, n=3)\n",
      "   - Accesses maintenance technician expertise\n",
      "   - Provides practical troubleshooting tips\n",
      "   - Includes lessons learned from field experience\n",
      "\n",
      "4. generate_incident_report(error_code, error_name, root_cause, \n",
      "                           repair_instructions, machine_id)\n",
      "   - Creates formal incident documentation\n",
      "   - Stores structured repair procedures\n",
      "   - Enables knowledge base building\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize the agent workflow\n",
    "import textwrap\n",
    "\n",
    "# Agent flow diagram\n",
    "flow_diagram = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     FAILURE AGENT WORKFLOW                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                              START\n",
    "                                â”‚\n",
    "                                â–¼\n",
    "                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”‚    AGENT     â”‚\n",
    "                        â”‚  Node: Call  â”‚\n",
    "                        â”‚ Language LLM â”‚\n",
    "                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                â”‚\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚                       â”‚\n",
    "              Tool Calls?              No Calls\n",
    "                    â”‚                       â”‚\n",
    "                    â–¼                       â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚    TOOLS     â”‚         â”‚   AGENT SENDS   â”‚\n",
    "            â”‚ Node: Processâ”‚         â”‚   FINAL MESSAGE â”‚\n",
    "            â”‚ Tool Results â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
    "                    â”‚                        â–¼\n",
    "                    â”‚                       END\n",
    "                    â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â–²\n",
    "                            â”‚\n",
    "        Continue loop while agent has tool calls\n",
    "\n",
    "\n",
    "TOOLS AVAILABLE TO THE AGENT:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "1. retrieve_manual(query, n=3)\n",
    "   - Searches technical documentation\n",
    "   - Returns relevant manuals and procedures\n",
    "   - Helps understand error codes and prevention\n",
    "\n",
    "2. retrieve_work_orders(query, n=3)\n",
    "   - Finds related maintenance history\n",
    "   - Shows previous occurrences and resolutions\n",
    "   - Provides proven repair strategies\n",
    "\n",
    "3. retrieve_interviews(query, n=3)\n",
    "   - Accesses maintenance technician expertise\n",
    "   - Provides practical troubleshooting tips\n",
    "   - Includes lessons learned from field experience\n",
    "\n",
    "4. generate_incident_report(error_code, error_name, root_cause, \n",
    "                           repair_instructions, machine_id)\n",
    "   - Creates formal incident documentation\n",
    "   - Stores structured repair procedures\n",
    "   - Enables knowledge base building\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\"\"\"\n",
    "\n",
    "print(flow_diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ee53e",
   "metadata": {},
   "source": [
    "## 7. Visualize the Agent Flow\n",
    "\n",
    "Visualize the graph structure to understand the agent's workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef345ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE INCIDENT REPORT OUTPUT\n",
      "================================================================================\n",
      "{\n",
      "  \"incident_id\": \"INC-1001\",\n",
      "  \"timestamp\": \"2025-01-26T10:30:00\",\n",
      "  \"error_code\": \"E001\",\n",
      "  \"error_name\": \"Motor Overheating\",\n",
      "  \"machine_id\": \"MACH-2024-001\",\n",
      "  \"root_cause\": \"The motor coolant pump is clogged with debris, preventing proper heat dissipation\",\n",
      "  \"repair_instructions\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"description\": \"Turn off the machine and allow it to cool for 30 minutes\"\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"description\": \"Remove the coolant pump cover using a 15mm wrench\"\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"description\": \"Inspect the pump inlet for debris and clean if necessary\"\n",
      "    },\n",
      "    {\n",
      "      \"step\": 4,\n",
      "      \"description\": \"Check coolant levels and top up with ISO VG 32 coolant if needed\"\n",
      "    },\n",
      "    {\n",
      "      \"step\": 5,\n",
      "      \"description\": \"Replace the pump cover and run the machine at idle for 5 minutes\"\n",
      "    },\n",
      "    {\n",
      "      \"step\": 6,\n",
      "      \"description\": \"Monitor temperature for 30 minutes and confirm normal operation\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "âœ“ Generated incident reports are stored for future reference\n"
     ]
    }
   ],
   "source": [
    "# Example: Simulated incident report that would be generated\n",
    "example_incident_report = {\n",
    "    \"incident_id\": \"INC-1001\",\n",
    "    \"timestamp\": \"2025-01-26T10:30:00\",\n",
    "    \"error_code\": \"E001\",\n",
    "    \"error_name\": \"Motor Overheating\",\n",
    "    \"machine_id\": \"MACH-2024-001\",\n",
    "    \"root_cause\": \"The motor coolant pump is clogged with debris, preventing proper heat dissipation\",\n",
    "    \"repair_instructions\": [\n",
    "        {\n",
    "            \"step\": 1,\n",
    "            \"description\": \"Turn off the machine and allow it to cool for 30 minutes\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 2,\n",
    "            \"description\": \"Remove the coolant pump cover using a 15mm wrench\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 3,\n",
    "            \"description\": \"Inspect the pump inlet for debris and clean if necessary\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 4,\n",
    "            \"description\": \"Check coolant levels and top up with ISO VG 32 coolant if needed\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 5,\n",
    "            \"description\": \"Replace the pump cover and run the machine at idle for 5 minutes\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 6,\n",
    "            \"description\": \"Monitor temperature for 30 minutes and confirm normal operation\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLE INCIDENT REPORT OUTPUT\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(example_incident_report, indent=2))\n",
    "\n",
    "print(\"\\nâœ“ Generated incident reports are stored for future reference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6b4351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST SCENARIO 2: BELT MISALIGNMENT (E002)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'HumanMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m      6\u001b[39m test_input_2 = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mAlert Details:\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m- Error Code: E002\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33mPlease analyze this failure and generate an incident report.\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     17\u001b[39m initial_state_2 = {\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mHumanMessage\u001b[49m(content=test_input_2)]\n\u001b[32m     19\u001b[39m }\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“¨ Input Alert:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(test_input_2)\n",
      "\u001b[31mNameError\u001b[39m: name 'HumanMessage' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Scenario 2: Belt Misalignment\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST SCENARIO 2: BELT MISALIGNMENT (E002)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_input_2 = \"\"\"\n",
    "Alert Details:\n",
    "- Error Code: E002\n",
    "- Error Name: Belt Misalignment\n",
    "- Machine ID: MACH-2024-005\n",
    "- Timestamp: 2025-01-26 11:15:00\n",
    "- Severity: Medium\n",
    "\n",
    "Please analyze this failure and generate an incident report.\n",
    "\"\"\"\n",
    "\n",
    "initial_state_2 = {\n",
    "    \"messages\": [HumanMessage(content=test_input_2)]\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“¨ Input Alert:\")\n",
    "print(test_input_2)\n",
    "print(\"\\nðŸ¤– Agent Processing...\")\n",
    "print(\"\\nThe agent would:\")\n",
    "print(\"  1. Retrieve technical documentation about belt alignment\")\n",
    "print(\"  2. Find previous work orders with similar issues\")\n",
    "print(\"  3. Access maintenance technician expertise on belt alignment\")\n",
    "print(\"  4. Create comprehensive incident report with step-by-step repair guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da168c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST SCENARIO 1: MOTOR OVERHEATING (E001)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'HumanMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m      6\u001b[39m test_input_1 = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mAlert Details:\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m- Error Code: E001\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33mwith repair instructions.\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     18\u001b[39m initial_state_1 = {\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mHumanMessage\u001b[49m(content=test_input_1)]\n\u001b[32m     20\u001b[39m }\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“¨ Input Alert:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(test_input_1)\n",
      "\u001b[31mNameError\u001b[39m: name 'HumanMessage' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Scenario 1: Motor Overheating\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST SCENARIO 1: MOTOR OVERHEATING (E001)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_input_1 = \"\"\"\n",
    "Alert Details:\n",
    "- Error Code: E001\n",
    "- Error Name: Motor Overheating\n",
    "- Machine ID: MACH-2024-001\n",
    "- Timestamp: 2025-01-26 10:30:00\n",
    "- Severity: High\n",
    "\n",
    "Please analyze this failure, retrieve relevant information, and generate an incident report \n",
    "with repair instructions.\n",
    "\"\"\"\n",
    "\n",
    "initial_state_1 = {\n",
    "    \"messages\": [HumanMessage(content=test_input_1)]\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“¨ Input Alert:\")\n",
    "print(test_input_1)\n",
    "print(\"\\nðŸ¤– Agent Processing...\")\n",
    "\n",
    "# Run the agent (Note: this requires async context, so we'll show the structure)\n",
    "print(\"\\nNote: In a production environment, use: await failure_agent.ainvoke(initial_state_1)\")\n",
    "print(\"The agent would then:\")\n",
    "print(\"  1. Call retrieve_manual('E001 motor overheating')\")\n",
    "print(\"  2. Call retrieve_work_orders('motor overheating')\")\n",
    "print(\"  3. Call retrieve_interviews('motor overheating diagnosis')\")\n",
    "print(\"  4. Generate incident report with root cause and repair steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9470c42",
   "metadata": {},
   "source": [
    "## 6. Test the Failure Agent\n",
    "\n",
    "Execute the failure agent with sample failure scenarios and observe how it diagnoses issues and suggests solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6322f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Failure Agent graph compiled successfully\n"
     ]
    }
   ],
   "source": [
    "# Build the StateGraph\n",
    "workflow = StateGraph(FailureAgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", process_tool_calls)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "failure_agent = workflow.compile()\n",
    "\n",
    "print(\"âœ“ Failure Agent graph compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee70e92",
   "metadata": {},
   "source": [
    "## 5. Compile the Graph\n",
    "\n",
    "Create the StateGraph and compile it into an executable agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d220c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Routing logic defined\n"
     ]
    }
   ],
   "source": [
    "# Define the Routing Logic\n",
    "def should_continue(state: FailureAgentState) -> str:\n",
    "    \"\"\"\n",
    "    Decide whether to continue with tool execution or end the conversation.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the last message has tool calls, route to the tools node\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, end the agent\n",
    "    return END\n",
    "\n",
    "print(\"âœ“ Routing logic defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc5a0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Tool execution node defined\n"
     ]
    }
   ],
   "source": [
    "# Define the Tool Execution Node\n",
    "async def process_tool_calls(state: FailureAgentState) -> FailureAgentState:\n",
    "    \"\"\"\n",
    "    Process tool calls from the agent and return the results.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    tool_results = []\n",
    "    \n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_input = tool_call[\"args\"]\n",
    "            \n",
    "            print(f\"\\nðŸ”§ Executing tool: {tool_name}\")\n",
    "            print(f\"   Input: {tool_input}\")\n",
    "            \n",
    "            # Find and execute the tool\n",
    "            for tool in tools:\n",
    "                if tool.name == tool_name:\n",
    "                    result = await tool.ainvoke(tool_input)\n",
    "                    print(f\"   Result: {result[:100]}...\")\n",
    "                    \n",
    "                    tool_message = ToolMessage(\n",
    "                        content=result,\n",
    "                        tool_call_id=tool_call[\"id\"]\n",
    "                    )\n",
    "                    tool_results.append(tool_message)\n",
    "                    break\n",
    "    \n",
    "    return {\n",
    "        \"messages\": tool_results\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Tool execution node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83f2a50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent node defined\n"
     ]
    }
   ],
   "source": [
    "# Define the Agent Node\n",
    "async def agent_node(state: FailureAgentState) -> FailureAgentState:\n",
    "    \"\"\"\n",
    "    The agent node processes messages and calls the LLM to decide next steps.\n",
    "    \"\"\"\n",
    "    # Create the prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are the Failure Agent. Your role is to:\n",
    "1. Receive alert details about machine failures\n",
    "2. Retrieve additional context from manuals, work orders, and maintenance expertise\n",
    "3. Analyze the root cause of the failure\n",
    "4. Generate a comprehensive incident report with repair instructions\n",
    "\n",
    "Use your tools strategically to gather all necessary information before generating the incident report.\n",
    "After the incident report is generated, acknowledge the completion with a brief summary.\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ])\n",
    "    \n",
    "    # Format the messages\n",
    "    formatted_prompt = await prompt.ainvoke({\"messages\": state[\"messages\"]})\n",
    "    \n",
    "    # Get the response from the model\n",
    "    response = await llm_with_tools.ainvoke(formatted_prompt)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Agent node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61f4d90e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize the LLM\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Bind tools to the model\u001b[39;00m\n\u001b[32m      9\u001b[39m llm_with_tools = llm.bind_tools(tools)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/multiagent-predictive-maintenance/.venv/lib/python3.13/site-packages/langchain_core/load/serializable.py:117\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/multiagent-predictive-maintenance/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:996\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    986\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_async_client = httpx.AsyncClient(\n\u001b[32m    987\u001b[39m             proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy, verify=global_ssl_context\n\u001b[32m    988\u001b[39m         )\n\u001b[32m    989\u001b[39m     async_specific = {\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_async_client\n\u001b[32m    991\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_async_httpx_client(\n\u001b[32m   (...)\u001b[39m\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: async_api_key_value,\n\u001b[32m    995\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_async_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43masync_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1000\u001b[39m     \u001b[38;5;28mself\u001b[39m.async_client = \u001b[38;5;28mself\u001b[39m.root_async_client.chat.completions\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/multiagent-predictive-maintenance/.venv/lib/python3.13/site-packages/openai/_client.py:488\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    486\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    490\u001b[39m     )\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Bind tools to the model\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"âœ“ Language model configured with tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e0595",
   "metadata": {},
   "source": [
    "## 4. Build the Agent Graph\n",
    "\n",
    "Construct the LangGraph workflow by defining nodes for agent logic, tool execution, and decision-making processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f0c32f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Tool functions defined and registered\n"
     ]
    }
   ],
   "source": [
    "# Define Tool Functions\n",
    "\n",
    "@tool\n",
    "def retrieve_manual(query: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant technical manuals for the alert via semantic search.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for technical documentation\n",
    "        n: Number of results to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing relevant manual excerpts\n",
    "    \"\"\"\n",
    "    # Mock implementation - in production would use vector search with embeddings\n",
    "    results = []\n",
    "    for error_code, manual in MOCK_MANUALS.items():\n",
    "        if query.lower() in manual[\"title\"].lower() or query.lower() in manual[\"content\"].lower():\n",
    "            results.append({\n",
    "                \"error_code\": error_code,\n",
    "                \"title\": manual[\"title\"],\n",
    "                \"content\": manual[\"content\"],\n",
    "                \"relevance_score\": 0.95\n",
    "            })\n",
    "    \n",
    "    return json.dumps(results[:n])\n",
    "\n",
    "@tool\n",
    "def retrieve_work_orders(query: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve related work orders for the alert via semantic search.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for work orders\n",
    "        n: Number of results to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing related work order information\n",
    "    \"\"\"\n",
    "    # Mock implementation - in production would use vector search\n",
    "    results = []\n",
    "    for wo_id, wo in MOCK_WORKORDERS.items():\n",
    "        if query.lower() in wo[\"title\"].lower() or query.lower() in wo[\"observations\"].lower():\n",
    "            results.append({\n",
    "                \"work_order_id\": wo_id,\n",
    "                \"title\": wo[\"title\"],\n",
    "                \"observations\": wo[\"observations\"],\n",
    "                \"date\": wo[\"date\"],\n",
    "                \"relevance_score\": 0.88\n",
    "            })\n",
    "    \n",
    "    return json.dumps(results[:n])\n",
    "\n",
    "@tool\n",
    "def retrieve_interviews(query: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve interviews and expertise related to the alert via semantic search.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for maintenance expertise\n",
    "        n: Number of results to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing relevant interview excerpts\n",
    "    \"\"\"\n",
    "    # Mock implementation - in production would use vector search\n",
    "    results = []\n",
    "    for int_id, interview in MOCK_INTERVIEWS.items():\n",
    "        if query.lower() in interview[\"text\"].lower() or query.lower() in interview[\"technician\"].lower():\n",
    "            results.append({\n",
    "                \"interview_id\": int_id,\n",
    "                \"technician\": interview[\"technician\"],\n",
    "                \"expertise\": interview[\"text\"],\n",
    "                \"relevance_score\": 0.92\n",
    "            })\n",
    "    \n",
    "    return json.dumps(results[:n])\n",
    "\n",
    "@tool\n",
    "def generate_incident_report(\n",
    "    error_code: str,\n",
    "    error_name: str,\n",
    "    root_cause: str,\n",
    "    repair_instructions: List[Dict[str, Any]],\n",
    "    machine_id: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate and store an incident report for the failure alert.\n",
    "    \n",
    "    Args:\n",
    "        error_code: The error code for the incident\n",
    "        error_name: Human-readable name of the error\n",
    "        root_cause: Root cause analysis inferred from context\n",
    "        repair_instructions: List of repair steps (3-6 steps)\n",
    "        machine_id: ID of the affected machine\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with incident report confirmation\n",
    "    \"\"\"\n",
    "    report = {\n",
    "        \"incident_id\": f\"INC-{len(INCIDENT_REPORTS) + 1001}\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"error_code\": error_code,\n",
    "        \"error_name\": error_name,\n",
    "        \"root_cause\": root_cause,\n",
    "        \"repair_instructions\": repair_instructions,\n",
    "        \"machine_id\": machine_id,\n",
    "        \"status\": \"created\"\n",
    "    }\n",
    "    \n",
    "    INCIDENT_REPORTS.append(report)\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"success\": True,\n",
    "        \"incident_id\": report[\"incident_id\"],\n",
    "        \"message\": f\"Incident report created successfully\"\n",
    "    })\n",
    "\n",
    "# Get all tools\n",
    "tools = [retrieve_manual, retrieve_work_orders, retrieve_interviews, generate_incident_report]\n",
    "\n",
    "print(\"âœ“ Tool functions defined and registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f06e7db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Mock database initialized\n"
     ]
    }
   ],
   "source": [
    "# Mock database for demonstration\n",
    "# In production, these would connect to MongoDB with vector search\n",
    "\n",
    "MOCK_MANUALS = {\n",
    "    \"E001\": {\n",
    "        \"title\": \"Error E001: Motor Overheating\",\n",
    "        \"content\": \"The motor may be overheating due to excessive load or insufficient cooling. Check coolant levels and ensure ventilation is not blocked.\"\n",
    "    },\n",
    "    \"E002\": {\n",
    "        \"title\": \"Error E002: Belt Misalignment\",\n",
    "        \"content\": \"Belt misalignment can cause uneven wear and reduced efficiency. Inspect belt tension and alignment guides.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "MOCK_WORKORDERS = {\n",
    "    \"WO-1001\": {\n",
    "        \"title\": \"Replace Motor Bearings\",\n",
    "        \"observations\": \"Previous motor failure resolved by replacing worn bearings\",\n",
    "        \"date\": \"2025-12-15\"\n",
    "    },\n",
    "    \"WO-1002\": {\n",
    "        \"title\": \"Coolant System Maintenance\",\n",
    "        \"observations\": \"Coolant flush and filter replacement prevented overheating\",\n",
    "        \"date\": \"2025-11-20\"\n",
    "    }\n",
    "}\n",
    "\n",
    "MOCK_INTERVIEWS = {\n",
    "    \"INT-001\": {\n",
    "        \"technician\": \"John Smith\",\n",
    "        \"text\": \"When we see E001 errors, the first thing to check is the coolant pump. 9 out of 10 times it's just debris in the pump.\"\n",
    "    },\n",
    "    \"INT-002\": {\n",
    "        \"technician\": \"Maria Garcia\",\n",
    "        \"text\": \"E002 belt issues often happen when the drive sprockets are misaligned. Check both ends of the shaft alignment.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "INCIDENT_REPORTS = []\n",
    "\n",
    "print(\"âœ“ Mock database initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b4fe0",
   "metadata": {},
   "source": [
    "## 3. Create Tool Functions\n",
    "\n",
    "The failure agent uses four main tools to diagnose failures and generate incident reports:\n",
    "- **retrieve_manual**: Search technical manuals for relevant information\n",
    "- **retrieve_work_orders**: Find related maintenance work orders\n",
    "- **retrieve_interviews**: Access maintenance staff expertise and historical insights\n",
    "- **generate_incident_report**: Create and store incident reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba211231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ State schema defined\n"
     ]
    }
   ],
   "source": [
    "# Define State Schema\n",
    "from typing import TypedDict\n",
    "\n",
    "class FailureAgentState(TypedDict):\n",
    "    \"\"\"State schema for the Failure Agent\"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    \n",
    "print(\"âœ“ State schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8e0de",
   "metadata": {},
   "source": [
    "## 2. Define the State Schema\n",
    "\n",
    "The state schema maintains the conversation history and messages throughout the agent's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3accc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Optional, List\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# LangChain and LangGraph imports\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tool\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dotenv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff5e7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in ./.venv/lib/python3.13/site-packages (0.9.9)\n",
      "Requirement already satisfied: pymongo in ./.venv/lib/python3.13/site-packages (4.16.0)\n",
      "Requirement already satisfied: voyageai in ./.venv/lib/python3.13/site-packages (0.3.7)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.13/site-packages (2.15.0)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.13/site-packages (1.2.7)\n",
      "Requirement already satisfied: asyncio in ./.venv/lib/python3.13/site-packages (4.0.0)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (from dotenv) (1.2.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=2.6.1 in ./.venv/lib/python3.13/site-packages (from pymongo) (2.8.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.13/site-packages (from voyageai) (3.13.3)\n",
      "Requirement already satisfied: aiolimiter in ./.venv/lib/python3.13/site-packages (from voyageai) (1.2.1)\n",
      "Requirement already satisfied: ffmpeg-python in ./.venv/lib/python3.13/site-packages (from voyageai) (0.2.0)\n",
      "Requirement already satisfied: langchain-text-splitters>=0.3.8 in ./.venv/lib/python3.13/site-packages (from voyageai) (1.1.0)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./.venv/lib/python3.13/site-packages (from voyageai) (2.4.1)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from voyageai) (12.1.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in ./.venv/lib/python3.13/site-packages (from voyageai) (2.12.5)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from voyageai) (2.32.5)\n",
      "Requirement already satisfied: tenacity in ./.venv/lib/python3.13/site-packages (from voyageai) (9.1.2)\n",
      "Requirement already satisfied: tokenizers>=0.14.0 in ./.venv/lib/python3.13/site-packages (from voyageai) (0.22.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.13/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (0.4.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in ./.venv/lib/python3.13/site-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in ./.venv/lib/python3.13/site-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in ./.venv/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in ./.venv/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./.venv/lib/python3.13/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.13/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (0.25.0)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Using cached tiktoken-0.12.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2026.1.15-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->voyageai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->voyageai) (2.6.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./.venv/lib/python3.13/site-packages (from tokenizers>=0.14.0->voyageai) (1.3.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (1.2.0)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (0.21.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.22.0)\n",
      "Requirement already satisfied: future in ./.venv/lib/python3.13/site-packages (from ffmpeg-python->voyageai) (1.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (8.3.1)\n",
      "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
      "Using cached tiktoken-0.12.0-cp313-cp313-macosx_11_0_arm64.whl (993 kB)\n",
      "Downloading regex-2026.1.15-cp313-cp313-macosx_11_0_arm64.whl (288 kB)\n",
      "Installing collected packages: regex, tiktoken, langchain-openai\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [langchain-openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-openai-1.1.7 regex-2026.1.15 tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "# Installing a libraries' directly in the notebook\n",
    "!pip install dotenv pymongo voyageai openai  langchain asyncio langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e8bff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, Optional, List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain and LangGraph imports\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import StateSnapshot\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599cf02",
   "metadata": {},
   "source": [
    "# Failure Agent using LangGraph\n",
    "\n",
    "This notebook implements a Python version of the failure agent that processes machine failure alerts and generates incident reports. The agent uses LangGraph as the agentic framework to coordinate multi-step reasoning and tool execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16dc670",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates a production-ready failure agent implementation using LangGraph. The agent:\n",
    "\n",
    "- **Receives** machine failure alerts with error codes and details\n",
    "- **Analyzes** the failure using multiple retrieval tools\n",
    "- **Synthesizes** information from technical documentation, maintenance history, and expert knowledge\n",
    "- **Generates** comprehensive incident reports with step-by-step repair instructions\n",
    "- **Maintains** conversation history for audit and learning purposes\n",
    "\n",
    "The LangGraph framework provides:\n",
    "- Clear workflow definition with nodes and edges\n",
    "- Automatic tool binding and execution\n",
    "- Message history management\n",
    "- Extensibility for adding new tools and decision logic\n",
    "- Support for async operations\n",
    "\n",
    "To use this in production:\n",
    "1. Replace mock databases with real MongoDB connections and vector embeddings\n",
    "2. Configure OpenAI API credentials\n",
    "3. Add persistent storage for incident reports\n",
    "4. Implement checkpointing for long-running operations\n",
    "5. Add error handling and retry logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8df65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph structure information\n",
    "graph_info = f\"\"\"\n",
    "AGENT GRAPH STRUCTURE:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Nodes:\n",
    "  - agent: Processes input and calls LLM with tool bindings\n",
    "  - tools: Executes tool calls and returns results\n",
    "\n",
    "Edges:\n",
    "  - START â†’ agent: Entry point\n",
    "  - agent â†’ tools: When agent calls tools\n",
    "  - tools â†’ agent: Loop back for next reasoning step\n",
    "  - agent â†’ END: When no more tool calls needed\n",
    "\n",
    "State Schema:\n",
    "  - messages: Annotated list of BaseMessage objects\n",
    "              (Maintains conversation history)\n",
    "\n",
    "Routing Logic:\n",
    "  - If last message has tool_calls â†’ route to \"tools\" node\n",
    "  - Otherwise â†’ route to END (terminate)\n",
    "\n",
    "Execution Flow:\n",
    "  1. User provides alert details via HumanMessage\n",
    "  2. Agent receives message and decides what tools to use\n",
    "  3. Agent calls appropriate retrieval and analysis tools\n",
    "  4. Tool results returned as ToolMessages\n",
    "  5. Agent synthesizes results and generates incident report\n",
    "  6. Agent generates final summary\n",
    "  7. Graph terminates with complete incident documentation\n",
    "\"\"\"\n",
    "\n",
    "print(graph_info)\n",
    "\n",
    "# Show how to use the agent\n",
    "usage_example = \"\"\"\n",
    "USAGE EXAMPLE:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Input an alert\n",
    "initial_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"Alert: Machine MACH-001 reported error E001 at 10:30 AM\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Run the agent asynchronously\n",
    "import asyncio\n",
    "result = await failure_agent.ainvoke(initial_state)\n",
    "\n",
    "# Access the conversation history\n",
    "for message in result[\"messages\"]:\n",
    "    print(f\"{message.__class__.__name__}: {message.content}\")\n",
    "\n",
    "# Incidents are stored in INCIDENT_REPORTS for later retrieval\n",
    "print(f\"Total incidents created: {len(INCIDENT_REPORTS)}\")\n",
    "\"\"\"\n",
    "\n",
    "print(usage_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the agent workflow\n",
    "import textwrap\n",
    "\n",
    "# Agent flow diagram\n",
    "flow_diagram = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     FAILURE AGENT WORKFLOW                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                              START\n",
    "                                â”‚\n",
    "                                â–¼\n",
    "                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”‚    AGENT     â”‚\n",
    "                        â”‚  Node: Call  â”‚\n",
    "                        â”‚ Language LLM â”‚\n",
    "                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                â”‚\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚                       â”‚\n",
    "              Tool Calls?              No Calls\n",
    "                    â”‚                       â”‚\n",
    "                    â–¼                       â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚    TOOLS     â”‚         â”‚   AGENT SENDS   â”‚\n",
    "            â”‚ Node: Processâ”‚         â”‚   FINAL MESSAGE â”‚\n",
    "            â”‚ Tool Results â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
    "                    â”‚                        â–¼\n",
    "                    â”‚                       END\n",
    "                    â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â–²\n",
    "                            â”‚\n",
    "        Continue loop while agent has tool calls\n",
    "\n",
    "\n",
    "TOOLS AVAILABLE TO THE AGENT:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "1. retrieve_manual(query, n=3)\n",
    "   - Searches technical documentation\n",
    "   - Returns relevant manuals and procedures\n",
    "   - Helps understand error codes and prevention\n",
    "\n",
    "2. retrieve_work_orders(query, n=3)\n",
    "   - Finds related maintenance history\n",
    "   - Shows previous occurrences and resolutions\n",
    "   - Provides proven repair strategies\n",
    "\n",
    "3. retrieve_interviews(query, n=3)\n",
    "   - Accesses maintenance technician expertise\n",
    "   - Provides practical troubleshooting tips\n",
    "   - Includes lessons learned from field experience\n",
    "\n",
    "4. generate_incident_report(error_code, error_name, root_cause, \n",
    "                           repair_instructions, machine_id)\n",
    "   - Creates formal incident documentation\n",
    "   - Stores structured repair procedures\n",
    "   - Enables knowledge base building\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\"\"\"\n",
    "\n",
    "print(flow_diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e674b0a4",
   "metadata": {},
   "source": [
    "## 8. Visualize the Agent Flow\n",
    "\n",
    "Visualize the graph structure to understand the agent's workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eeac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simulated incident report that would be generated\n",
    "example_incident_report = {\n",
    "    \"incident_id\": \"INC-1001\",\n",
    "    \"timestamp\": \"2025-01-26T10:30:00\",\n",
    "    \"error_code\": \"E001\",\n",
    "    \"error_name\": \"Motor Overheating\",\n",
    "    \"machine_id\": \"MACH-2024-001\",\n",
    "    \"root_cause\": \"The motor coolant pump is clogged with debris, preventing proper heat dissipation\",\n",
    "    \"repair_instructions\": [\n",
    "        {\n",
    "            \"step\": 1,\n",
    "            \"description\": \"Turn off the machine and allow it to cool for 30 minutes\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 2,\n",
    "            \"description\": \"Remove the coolant pump cover using a 15mm wrench\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 3,\n",
    "            \"description\": \"Inspect the pump inlet for debris and clean if necessary\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 4,\n",
    "            \"description\": \"Check coolant levels and top up with ISO VG 32 coolant if needed\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 5,\n",
    "            \"description\": \"Replace the pump cover and run the machine at idle for 5 minutes\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 6,\n",
    "            \"description\": \"Monitor temperature for 30 minutes and confirm normal operation\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLE INCIDENT REPORT OUTPUT\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(example_incident_report, indent=2))\n",
    "\n",
    "print(\"\\nâœ“ Generated incident reports are stored for future reference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55305f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Scenario 2: Belt Misalignment\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST SCENARIO 2: BELT MISALIGNMENT (E002)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_input_2 = \"\"\"\n",
    "Alert Details:\n",
    "- Error Code: E002\n",
    "- Error Name: Belt Misalignment\n",
    "- Machine ID: MACH-2024-005\n",
    "- Timestamp: 2025-01-26 11:15:00\n",
    "- Severity: Medium\n",
    "\n",
    "Please analyze this failure and generate an incident report.\n",
    "\"\"\"\n",
    "\n",
    "initial_state_2 = {\n",
    "    \"messages\": [HumanMessage(content=test_input_2)]\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“¨ Input Alert:\")\n",
    "print(test_input_2)\n",
    "print(\"\\nðŸ¤– Agent Processing...\")\n",
    "print(\"\\nThe agent would:\")\n",
    "print(\"  1. Retrieve technical documentation about belt alignment\")\n",
    "print(\"  2. Find previous work orders with similar issues\")\n",
    "print(\"  3. Access maintenance technician expertise on belt alignment\")\n",
    "print(\"  4. Create comprehensive incident report with step-by-step repair guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f384853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Scenario 1: Motor Overheating\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST SCENARIO 1: MOTOR OVERHEATING (E001)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_input_1 = \"\"\"\n",
    "Alert Details:\n",
    "- Error Code: E001\n",
    "- Error Name: Motor Overheating\n",
    "- Machine ID: MACH-2024-001\n",
    "- Timestamp: 2025-01-26 10:30:00\n",
    "- Severity: High\n",
    "\n",
    "Please analyze this failure, retrieve relevant information, and generate an incident report \n",
    "with repair instructions.\n",
    "\"\"\"\n",
    "\n",
    "initial_state_1 = {\n",
    "    \"messages\": [HumanMessage(content=test_input_1)]\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“¨ Input Alert:\")\n",
    "print(test_input_1)\n",
    "print(\"\\nðŸ¤– Agent Processing...\")\n",
    "\n",
    "# Run the agent (Note: this requires async context, so we'll show the structure)\n",
    "print(\"\\nNote: In a production environment, use: await failure_agent.ainvoke(initial_state_1)\")\n",
    "print(\"The agent would then:\")\n",
    "print(\"  1. Call retrieve_manual('E001 motor overheating')\")\n",
    "print(\"  2. Call retrieve_work_orders('motor overheating')\")\n",
    "print(\"  3. Call retrieve_interviews('motor overheating diagnosis')\")\n",
    "print(\"  4. Generate incident report with root cause and repair steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5f3c6",
   "metadata": {},
   "source": [
    "## 7. Test the Failure Agent\n",
    "\n",
    "Execute the failure agent with sample failure scenarios and observe how it diagnoses issues and suggests solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d90c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the StateGraph\n",
    "workflow = StateGraph(FailureAgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", process_tool_calls)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "failure_agent = workflow.compile()\n",
    "\n",
    "print(\"âœ“ Failure Agent graph compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61088092",
   "metadata": {},
   "source": [
    "## 6. Compile the Graph\n",
    "\n",
    "Create the StateGraph and compile it into an executable agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Routing Logic\n",
    "def should_continue(state: FailureAgentState) -> str:\n",
    "    \"\"\"\n",
    "    Decide whether to continue with tool execution or end the conversation.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the last message has tool calls, route to the tools node\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, end the agent\n",
    "    return END\n",
    "\n",
    "print(\"âœ“ Routing logic defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Tool Execution Node\n",
    "async def process_tool_calls(state: FailureAgentState) -> FailureAgentState:\n",
    "    \"\"\"\n",
    "    Process tool calls from the agent and return the results.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    tool_results = []\n",
    "    \n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_input = tool_call[\"args\"]\n",
    "            \n",
    "            print(f\"\\nðŸ”§ Executing tool: {tool_name}\")\n",
    "            print(f\"   Input: {tool_input}\")\n",
    "            \n",
    "            # Find and execute the tool\n",
    "            for tool in tools:\n",
    "                if tool.name == tool_name:\n",
    "                    result = await tool.ainvoke(tool_input)\n",
    "                    print(f\"   Result: {result[:100]}...\")\n",
    "                    \n",
    "                    tool_message = ToolMessage(\n",
    "                        content=result,\n",
    "                        tool_call_id=tool_call[\"id\"]\n",
    "                    )\n",
    "                    tool_results.append(tool_message)\n",
    "                    break\n",
    "    \n",
    "    return {\n",
    "        \"messages\": tool_results\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Tool execution node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4028d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Agent Node\n",
    "async def agent_node(state: FailureAgentState) -> FailureAgentState:\n",
    "    \"\"\"\n",
    "    The agent node processes messages and calls the LLM to decide next steps.\n",
    "    \"\"\"\n",
    "    # Create the prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are the Failure Agent. Your role is to:\n",
    "1. Receive alert details about machine failures\n",
    "2. Retrieve additional context from manuals, work orders, and maintenance expertise\n",
    "3. Analyze the root cause of the failure\n",
    "4. Generate a comprehensive incident report with repair instructions\n",
    "\n",
    "Use your tools strategically to gather all necessary information before generating the incident report.\n",
    "After the incident report is generated, acknowledge the completion with a brief summary.\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ])\n",
    "    \n",
    "    # Format the messages\n",
    "    formatted_prompt = await prompt.ainvoke({\"messages\": state[\"messages\"]})\n",
    "    \n",
    "    # Get the response from the model\n",
    "    response = await llm_with_tools.ainvoke(formatted_prompt)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Agent node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34cde256",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize the LLM\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Bind tools to the model\u001b[39;00m\n\u001b[32m      9\u001b[39m llm_with_tools = llm.bind_tools(tools)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/multiagent-predictive-maintenance/.venv/lib/python3.13/site-packages/langchain_core/load/serializable.py:117\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/multiagent-predictive-maintenance/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:996\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    986\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_async_client = httpx.AsyncClient(\n\u001b[32m    987\u001b[39m             proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy, verify=global_ssl_context\n\u001b[32m    988\u001b[39m         )\n\u001b[32m    989\u001b[39m     async_specific = {\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_async_client\n\u001b[32m    991\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_async_httpx_client(\n\u001b[32m   (...)\u001b[39m\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: async_api_key_value,\n\u001b[32m    995\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_async_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43masync_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1000\u001b[39m     \u001b[38;5;28mself\u001b[39m.async_client = \u001b[38;5;28mself\u001b[39m.root_async_client.chat.completions\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sw/multiagent-predictive-maintenance/.venv/lib/python3.13/site-packages/openai/_client.py:488\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    486\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    490\u001b[39m     )\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Bind tools to the model\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"âœ“ Language model configured with tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc1c15d",
   "metadata": {},
   "source": [
    "## 5. Build the Agent Graph\n",
    "\n",
    "Construct the LangGraph workflow by defining nodes for agent logic, tool execution, and decision-making processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "809d6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Tool functions defined and registered\n"
     ]
    }
   ],
   "source": [
    "# Define Tool Functions\n",
    "\n",
    "@tool\n",
    "def retrieve_manual(query: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant technical manuals for the alert via semantic search.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for technical documentation\n",
    "        n: Number of results to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing relevant manual excerpts\n",
    "    \"\"\"\n",
    "    # Mock implementation - in production would use vector search with embeddings\n",
    "    results = []\n",
    "    for error_code, manual in MOCK_MANUALS.items():\n",
    "        if query.lower() in manual[\"title\"].lower() or query.lower() in manual[\"content\"].lower():\n",
    "            results.append({\n",
    "                \"error_code\": error_code,\n",
    "                \"title\": manual[\"title\"],\n",
    "                \"content\": manual[\"content\"],\n",
    "                \"relevance_score\": 0.95\n",
    "            })\n",
    "    \n",
    "    return json.dumps(results[:n])\n",
    "\n",
    "@tool\n",
    "def retrieve_work_orders(query: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve related work orders for the alert via semantic search.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for work orders\n",
    "        n: Number of results to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing related work order information\n",
    "    \"\"\"\n",
    "    # Mock implementation - in production would use vector search\n",
    "    results = []\n",
    "    for wo_id, wo in MOCK_WORKORDERS.items():\n",
    "        if query.lower() in wo[\"title\"].lower() or query.lower() in wo[\"observations\"].lower():\n",
    "            results.append({\n",
    "                \"work_order_id\": wo_id,\n",
    "                \"title\": wo[\"title\"],\n",
    "                \"observations\": wo[\"observations\"],\n",
    "                \"date\": wo[\"date\"],\n",
    "                \"relevance_score\": 0.88\n",
    "            })\n",
    "    \n",
    "    return json.dumps(results[:n])\n",
    "\n",
    "@tool\n",
    "def retrieve_interviews(query: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve interviews and expertise related to the alert via semantic search.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for maintenance expertise\n",
    "        n: Number of results to return (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing relevant interview excerpts\n",
    "    \"\"\"\n",
    "    # Mock implementation - in production would use vector search\n",
    "    results = []\n",
    "    for int_id, interview in MOCK_INTERVIEWS.items():\n",
    "        if query.lower() in interview[\"text\"].lower() or query.lower() in interview[\"technician\"].lower():\n",
    "            results.append({\n",
    "                \"interview_id\": int_id,\n",
    "                \"technician\": interview[\"technician\"],\n",
    "                \"expertise\": interview[\"text\"],\n",
    "                \"relevance_score\": 0.92\n",
    "            })\n",
    "    \n",
    "    return json.dumps(results[:n])\n",
    "\n",
    "@tool\n",
    "def generate_incident_report(\n",
    "    error_code: str,\n",
    "    error_name: str,\n",
    "    root_cause: str,\n",
    "    repair_instructions: List[Dict[str, Any]],\n",
    "    machine_id: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate and store an incident report for the failure alert.\n",
    "    \n",
    "    Args:\n",
    "        error_code: The error code for the incident\n",
    "        error_name: Human-readable name of the error\n",
    "        root_cause: Root cause analysis inferred from context\n",
    "        repair_instructions: List of repair steps (3-6 steps)\n",
    "        machine_id: ID of the affected machine\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with incident report confirmation\n",
    "    \"\"\"\n",
    "    report = {\n",
    "        \"incident_id\": f\"INC-{len(INCIDENT_REPORTS) + 1001}\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"error_code\": error_code,\n",
    "        \"error_name\": error_name,\n",
    "        \"root_cause\": root_cause,\n",
    "        \"repair_instructions\": repair_instructions,\n",
    "        \"machine_id\": machine_id,\n",
    "        \"status\": \"created\"\n",
    "    }\n",
    "    \n",
    "    INCIDENT_REPORTS.append(report)\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"success\": True,\n",
    "        \"incident_id\": report[\"incident_id\"],\n",
    "        \"message\": f\"Incident report created successfully\"\n",
    "    })\n",
    "\n",
    "# Get all tools\n",
    "tools = [retrieve_manual, retrieve_work_orders, retrieve_interviews, generate_incident_report]\n",
    "\n",
    "print(\"âœ“ Tool functions defined and registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de2160c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Mock database initialized\n"
     ]
    }
   ],
   "source": [
    "# Mock database for demonstration\n",
    "# In production, these would connect to MongoDB with vector search\n",
    "\n",
    "MOCK_MANUALS = {\n",
    "    \"E001\": {\n",
    "        \"title\": \"Error E001: Motor Overheating\",\n",
    "        \"content\": \"The motor may be overheating due to excessive load or insufficient cooling. Check coolant levels and ensure ventilation is not blocked.\"\n",
    "    },\n",
    "    \"E002\": {\n",
    "        \"title\": \"Error E002: Belt Misalignment\",\n",
    "        \"content\": \"Belt misalignment can cause uneven wear and reduced efficiency. Inspect belt tension and alignment guides.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "MOCK_WORKORDERS = {\n",
    "    \"WO-1001\": {\n",
    "        \"title\": \"Replace Motor Bearings\",\n",
    "        \"observations\": \"Previous motor failure resolved by replacing worn bearings\",\n",
    "        \"date\": \"2025-12-15\"\n",
    "    },\n",
    "    \"WO-1002\": {\n",
    "        \"title\": \"Coolant System Maintenance\",\n",
    "        \"observations\": \"Coolant flush and filter replacement prevented overheating\",\n",
    "        \"date\": \"2025-11-20\"\n",
    "    }\n",
    "}\n",
    "\n",
    "MOCK_INTERVIEWS = {\n",
    "    \"INT-001\": {\n",
    "        \"technician\": \"John Smith\",\n",
    "        \"text\": \"When we see E001 errors, the first thing to check is the coolant pump. 9 out of 10 times it's just debris in the pump.\"\n",
    "    },\n",
    "    \"INT-002\": {\n",
    "        \"technician\": \"Maria Garcia\",\n",
    "        \"text\": \"E002 belt issues often happen when the drive sprockets are misaligned. Check both ends of the shaft alignment.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "INCIDENT_REPORTS = []\n",
    "\n",
    "print(\"âœ“ Mock database initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea9301",
   "metadata": {},
   "source": [
    "## 4. Create Tool Functions\n",
    "\n",
    "The failure agent uses four main tools to diagnose failures and generate incident reports:\n",
    "- **retrieve_manual**: Search technical manuals for relevant information\n",
    "- **retrieve_work_orders**: Find related maintenance work orders\n",
    "- **retrieve_interviews**: Access maintenance staff expertise and historical insights\n",
    "- **generate_incident_report**: Create and store incident reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c87f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ State schema defined\n"
     ]
    }
   ],
   "source": [
    "# Define State Schema\n",
    "from typing import TypedDict\n",
    "\n",
    "class FailureAgentState(TypedDict):\n",
    "    \"\"\"State schema for the Failure Agent\"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    \n",
    "print(\"âœ“ State schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6513e",
   "metadata": {},
   "source": [
    "## 3. Define the State Schema\n",
    "\n",
    "The state schema maintains the conversation history and messages throughout the agent's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b89df5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, Optional, List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain and LangGraph imports\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import StateSnapshot\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afcaa40",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Import necessary libraries including langchain, langgraph, and other dependencies for building the failure agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f946711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (1.2.1)\n",
      "Requirement already satisfied: pymongo in ./.venv/lib/python3.13/site-packages (4.16.0)\n",
      "Requirement already satisfied: voyageai in ./.venv/lib/python3.13/site-packages (0.3.7)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.13/site-packages (2.15.0)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.13/site-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.13/site-packages (1.1.7)\n",
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.13/site-packages (1.0.7)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=2.6.1 in ./.venv/lib/python3.13/site-packages (from pymongo) (2.8.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.13/site-packages (from voyageai) (3.13.3)\n",
      "Requirement already satisfied: aiolimiter in ./.venv/lib/python3.13/site-packages (from voyageai) (1.2.1)\n",
      "Requirement already satisfied: ffmpeg-python in ./.venv/lib/python3.13/site-packages (from voyageai) (0.2.0)\n",
      "Requirement already satisfied: langchain-text-splitters>=0.3.8 in ./.venv/lib/python3.13/site-packages (from voyageai) (1.1.0)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./.venv/lib/python3.13/site-packages (from voyageai) (2.4.1)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from voyageai) (12.1.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in ./.venv/lib/python3.13/site-packages (from voyageai) (2.12.5)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from voyageai) (2.32.5)\n",
      "Requirement already satisfied: tenacity in ./.venv/lib/python3.13/site-packages (from voyageai) (9.1.2)\n",
      "Requirement already satisfied: tokenizers>=0.14.0 in ./.venv/lib/python3.13/site-packages (from voyageai) (0.22.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.13/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (0.4.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in ./.venv/lib/python3.13/site-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in ./.venv/lib/python3.13/site-packages (from langgraph) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./.venv/lib/python3.13/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.13/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (0.25.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->voyageai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->voyageai) (2.6.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./.venv/lib/python3.13/site-packages (from tokenizers>=0.14.0->voyageai) (1.3.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (1.2.0)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (0.21.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.22.0)\n",
      "Requirement already satisfied: future in ./.venv/lib/python3.13/site-packages (from ffmpeg-python->voyageai) (1.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (8.3.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install python-dotenv pymongo voyageai openai langchain langchain-openai langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29907186",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries\n",
    "\n",
    "Install necessary packages for the failure agent implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
