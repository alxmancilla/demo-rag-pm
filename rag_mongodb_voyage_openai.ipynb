{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d586f25",
   "metadata": {},
   "source": [
    "# MongoDB Atlas + Voyage AI + OpenAI RAG Solution\n",
    "\n",
    "This notebook demonstrates a complete RAG (Retrieval-Augmented Generation) pipeline that:\n",
    "1. Ingests datasets (manuals and interviews) into MongoDB Atlas\n",
    "2. Generates embeddings using Voyage AI 3 model\n",
    "3. Creates vector indexes for similarity search\n",
    "4. Implements a RAG solution using OpenAI API for answering questions with context\n",
    "\n",
    "## Prerequisites\n",
    "- MongoDB Atlas cluster with Atlas Vector Search enabled\n",
    "- Voyage AI API key\n",
    "- OpenAI API key\n",
    "- Python packages: pymongo, voyageai, openai, pandas, python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb3ef7",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries and Configure Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2963f1f3",
   "metadata": {},
   "source": [
    "## Setup: Configure Virtual Environment and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a0d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in ./.venv/lib/python3.13/site-packages (0.9.9)\n",
      "Requirement already satisfied: pymongo in ./.venv/lib/python3.13/site-packages (4.16.0)\n",
      "Requirement already satisfied: voyageai in ./.venv/lib/python3.13/site-packages (0.3.7)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.13/site-packages (2.15.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (from dotenv) (1.2.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=2.6.1 in ./.venv/lib/python3.13/site-packages (from pymongo) (2.8.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.13/site-packages (from voyageai) (3.13.3)\n",
      "Requirement already satisfied: aiolimiter in ./.venv/lib/python3.13/site-packages (from voyageai) (1.2.1)\n",
      "Requirement already satisfied: ffmpeg-python in ./.venv/lib/python3.13/site-packages (from voyageai) (0.2.0)\n",
      "Requirement already satisfied: langchain-text-splitters>=0.3.8 in ./.venv/lib/python3.13/site-packages (from voyageai) (1.1.0)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./.venv/lib/python3.13/site-packages (from voyageai) (2.4.1)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from voyageai) (12.1.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in ./.venv/lib/python3.13/site-packages (from voyageai) (2.12.5)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from voyageai) (2.32.5)\n",
      "Requirement already satisfied: tenacity in ./.venv/lib/python3.13/site-packages (from voyageai) (9.1.2)\n",
      "Requirement already satisfied: tokenizers>=0.14.0 in ./.venv/lib/python3.13/site-packages (from voyageai) (0.22.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.13/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.10.8->voyageai) (0.4.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from langchain-text-splitters>=0.3.8->voyageai) (1.2.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters>=0.3.8->voyageai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters>=0.3.8->voyageai) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters>=0.3.8->voyageai) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters>=0.3.8->voyageai) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters>=0.3.8->voyageai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters>=0.3.8->voyageai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters>=0.3.8->voyageai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters>=0.3.8->voyageai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters>=0.3.8->voyageai) (0.25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->voyageai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->voyageai) (2.6.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./.venv/lib/python3.13/site-packages (from tokenizers>=0.14.0->voyageai) (1.3.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (1.2.0)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (0.21.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->voyageai) (1.22.0)\n",
      "Requirement already satisfied: future in ./.venv/lib/python3.13/site-packages (from ffmpeg-python->voyageai) (1.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing a libraries' directly in the notebook\n",
    "%pip install dotenv pymongo voyageai openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95be3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Status:\n",
      "✓ MongoDB URI configured: True\n",
      "✓ Voyage AI API key configured: True\n",
      "✓ OpenAI API key configured: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ServerSelectionTimeoutError\n",
    "from pymongo.operations import SearchIndexModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import voyageai\n",
    "#import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure MONGODB URI from environment variables\n",
    "MONGODB_URI = os.getenv(\"MONGODB_URI\")\n",
    "DATABASE_NAME = os.getenv(\"DATABASE_NAME\")\n",
    "\n",
    "# Configure LLM endpoint and API keys from environment variables\n",
    "LLM_API_ENDPOINT = os.getenv(\"LLM_API_ENDPOINT\")\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\")\n",
    "\n",
    "# Change the base URL\n",
    "VOYAGE_API_ENDPOINT = os.getenv(\"VOYAGE_API_ENDPOINT\")\n",
    "VOYAGE_API_KEY = os.getenv(\"VOYAGE_API_KEY\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")\n",
    "\n",
    "# Validate that API keys are available\n",
    "print(\"Configuration Status:\")\n",
    "print(f\"✓ MongoDB URI configured: {bool(MONGODB_URI)}\")\n",
    "print(f\"✓ Voyage AI API key configured: {bool(VOYAGE_API_KEY)}\")\n",
    "print(f\"✓ Voyage AI Embedding model configured: {bool(EMBEDDING_MODEL)}\")\n",
    "print(f\"✓ OpenAI API key configured: {bool(LLM_API_KEY)}\")\n",
    "\n",
    "# Initialize API clients\n",
    "if VOYAGE_API_KEY:\n",
    "    #voyageai.base_url = VOYAGE_API_ENDPOINT\n",
    "    voyage_client = voyageai.Client(api_key=VOYAGE_API_KEY)\n",
    "    \n",
    "if LLM_API_KEY:\n",
    "    #openai.base_url = LLM_API_ENDPOINT\n",
    "    llm_client = OpenAI( api_key=LLM_API_KEY )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978da6f",
   "metadata": {},
   "source": [
    "## Section 2: Connect to MongoDB Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3c83011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully connected to MongoDB Atlas\n",
      "✓ Database: pmd\n",
      "✓ Available collections: ['manuals', 'workorders', 'interviews']\n"
     ]
    }
   ],
   "source": [
    "def connect_to_mongodb(uri: str, db_name: str = DATABASE_NAME) -> tuple:\n",
    "    \"\"\"\n",
    "    Connect to MongoDB Atlas cluster\n",
    "    \n",
    "    Args:\n",
    "        uri: MongoDB connection string\n",
    "        db_name: Database name to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (client, database)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "        # Verify connection\n",
    "        client.admin.command('ping')\n",
    "        db = client[db_name]\n",
    "        print(f\"✓ Successfully connected to MongoDB Atlas\")\n",
    "        print(f\"✓ Database: {db_name}\")\n",
    "        return client, db\n",
    "    except ServerSelectionTimeoutError:\n",
    "        print(\"✗ Failed to connect to MongoDB Atlas. Check your connection string.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Connection error: {e}\")\n",
    "        raise\n",
    "\n",
    "# Connect to MongoDB\n",
    "if MONGODB_URI:\n",
    "    mongo_client, db = connect_to_mongodb(MONGODB_URI)\n",
    "    print(f\"✓ Available collections: {db.list_collection_names()}\")\n",
    "else:\n",
    "    print(\"✗ MONGODB_URI not configured. Please set the environment variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd92e9",
   "metadata": {},
   "source": [
    "## Section 3: Load and Ingest Datasets from Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8fb025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading datasets from: /Users/mancilla/sw/demo-rag-pm/data\n",
      "Available files: [PosixPath('data/manuals.json'), PosixPath('data/workorders.json'), PosixPath('data/maintenance_staff.json'), PosixPath('data/interviews.json'), PosixPath('data/inventory.json')]\n",
      "\n",
      "✓ Loaded data/manuals.json: 6 documents\n",
      "✓ Loaded data/interviews.json: 5 documents\n",
      "✓ Loaded data/workorders.json: 10 documents\n",
      "\n",
      "Dataset Summary:\n",
      "  - Manuals: 6 documents\n",
      "  - Interviews: 5 documents\n",
      "  - Work Orders: 10 documents\n"
     ]
    }
   ],
   "source": [
    "def load_json_dataset(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load a JSON dataset from file\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file\n",
    "        \n",
    "    Returns:\n",
    "        List of documents\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"✓ Loaded {file_path}: {len(data)} documents\")\n",
    "        return data if isinstance(data, list) else [data]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"✗ File not found: {file_path}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"✗ Error decoding JSON from {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Locate the data folder\n",
    "data_folder = Path(\"./data\")\n",
    "if not data_folder.exists():\n",
    "    print(f\"✗ Data folder not found at {data_folder.absolute()}\")\n",
    "    # Try alternative path\n",
    "    alt_path = Path(\"../data\")\n",
    "    if alt_path.exists():\n",
    "        data_folder = alt_path\n",
    "    else:\n",
    "        print(\"Please ensure the data folder exists in the workspace root\")\n",
    "\n",
    "print(f\"\\nLoading datasets from: {data_folder.absolute()}\")\n",
    "print(f\"Available files: {list(data_folder.glob('*'))}\\n\")\n",
    "\n",
    "# Load datasets\n",
    "manuals_data = load_json_dataset(str(data_folder / \"manuals.json\"))\n",
    "interviews_data = load_json_dataset(str(data_folder / \"interviews.json\"))\n",
    "workorders_data = load_json_dataset(str(data_folder / \"workorders.json\"))\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  - Manuals: {len(manuals_data)} documents\")\n",
    "print(f\"  - Interviews: {len(interviews_data)} documents\")\n",
    "print(f\"  - Work Orders: {len(workorders_data)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b15bb686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ingested 6 documents into 'manuals'\n",
      "✓ Ingested 5 documents into 'interviews'\n",
      "✓ Ingested 10 documents into 'workorders'\n",
      "\n",
      "✓ Data ingestion complete\n"
     ]
    }
   ],
   "source": [
    "def ingest_data_to_mongodb(db, collection_name: str, documents: List[Dict]) -> bool:\n",
    "    \"\"\"\n",
    "    Ingest documents into a MongoDB collection\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        collection_name: Name of the collection\n",
    "        documents: List of documents to insert\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        print(f\"✗ No documents to ingest into {collection_name}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        collection = db[collection_name]\n",
    "        # Drop existing collection to start fresh\n",
    "        collection.drop()\n",
    "        \n",
    "        # Insert documents\n",
    "        result = collection.insert_many(documents)\n",
    "        print(f\"✓ Ingested {len(result.inserted_ids)} documents into '{collection_name}'\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error ingesting data into {collection_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Ingest datasets into MongoDB\n",
    "if MONGODB_URI and manuals_data:\n",
    "    ingest_data_to_mongodb(db, \"manuals\", manuals_data)\n",
    "    \n",
    "if MONGODB_URI and interviews_data:\n",
    "    ingest_data_to_mongodb(db, \"interviews\", interviews_data)\n",
    "\n",
    "if MONGODB_URI and workorders_data:\n",
    "    ingest_data_to_mongodb(db, \"workorders\", workorders_data)\n",
    "\n",
    "print(\"\\n✓ Data ingestion complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d4fb2",
   "metadata": {},
   "source": [
    "## Section 4: Generate Embeddings Using Voyage AI 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8209481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Voyage AI embedding generation...\n",
      "✗ Error generating embeddings: Model voyageai-3-large is not supported. Supported models are ['voyage-4-large', 'voyage-4', 'voyage-4-lite', 'voyage-large-2-instruct', 'voyage-law-2', 'voyage-code-2', 'voyage-02', 'voyage-2', 'voyage-01', 'voyage-lite-01', 'voyage-lite-01-instruct', 'voyage-lite-02-instruct', 'voyage-multilingual-2', 'voyage-large-2'].\n",
      "✗ Embedding generation failed. Check API key and connectivity.\n"
     ]
    }
   ],
   "source": [
    "def extract_text_for_embedding(document: Dict[str, Any], text_fields: List[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Extract text content from a document for embedding\n",
    "    \n",
    "    Args:\n",
    "        document: The document to extract text from\n",
    "        text_fields: List of field names to extract (if None, uses sensible defaults)\n",
    "        \n",
    "    Returns:\n",
    "        Combined text string\n",
    "    \"\"\"\n",
    "    if text_fields is None:\n",
    "        # Default fields to check for text content\n",
    "        text_fields = ['text', 'title', 'observations']\n",
    "    \n",
    "    texts = []\n",
    "    for field in text_fields:\n",
    "        if field in document and document[field]:\n",
    "            value = document[field]\n",
    "            if isinstance(value, str):\n",
    "                texts.append(value)\n",
    "            elif isinstance(value, list):\n",
    "                texts.extend([str(v) for v in value if v])\n",
    "    \n",
    "    return \" \".join(texts)\n",
    "\n",
    "def generate_embeddings_batch(texts: List[str], model: str = EMBEDDING_MODEL) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Generate embeddings for a batch of texts using Voyage AI\n",
    "    \n",
    "    Args:\n",
    "        texts: List of texts to embed\n",
    "        model: Voyage AI model to use\n",
    "        \n",
    "    Returns:\n",
    "        List of embedding vectors\n",
    "    \"\"\"\n",
    "    if not texts:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Create embeddings using Voyage AI\n",
    "        response = voyage_client.embed(\n",
    "            texts=texts,\n",
    "            model=model,\n",
    "            input_type=\"document\"\n",
    "        )\n",
    "        embeddings = [e for e in response.embeddings]\n",
    "        print(f\"✓ Generated {len(embeddings)} embeddings using {model}\")\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error generating embeddings: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test embedding generation with a sample\n",
    "print(\"Testing Voyage AI embedding generation...\")\n",
    "test_texts = [\"This is a test document\", \"Another test text for embeddings\"]\n",
    "test_embeddings = generate_embeddings_batch(test_texts)\n",
    "if test_embeddings:\n",
    "    print(f\"✓ Sample embedding dimension: {len(test_embeddings[0])}\")\n",
    "else:\n",
    "    print(\"✗ Embedding generation failed. Check API key and connectivity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2b54e",
   "metadata": {},
   "source": [
    "## Section 5: Update Collections with Embeddings Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1292c9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GENERATING AND ADDING EMBEDDINGS TO COLLECTIONS\n",
      "============================================================\n",
      "\n",
      "Processing 6 documents in 'manuals'...\n",
      "✓ Generated 5 embeddings using voyage-3-large\n",
      "  ✓ Processed batch 1/2\n",
      "✓ Generated 1 embeddings using voyage-3-large\n",
      "  ✓ Processed batch 2/2\n",
      "✓ Updated 6 documents with embeddings in 'manuals'\n",
      "\n",
      "Processing 5 documents in 'interviews'...\n",
      "✓ Generated 5 embeddings using voyage-3-large\n",
      "  ✓ Processed batch 1/1\n",
      "✓ Updated 5 documents with embeddings in 'interviews'\n",
      "\n",
      "Processing 10 documents in 'workorders'...\n",
      "✓ Generated 10 embeddings using voyage-3-large\n",
      "  ✓ Processed batch 1/1\n",
      "✓ Updated 10 documents with embeddings in 'workorders'\n"
     ]
    }
   ],
   "source": [
    "def add_embeddings_to_collection(db, collection_name: str, batch_size: int = 10) -> bool:\n",
    "    \"\"\"\n",
    "    Generate embeddings for all documents in a collection and update them\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        collection_name: Name of the collection to process\n",
    "        batch_size: Number of documents to process per batch\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        collection = db[collection_name]\n",
    "        documents = list(collection.find({}))\n",
    "        \n",
    "        if not documents:\n",
    "            print(f\"✗ No documents found in collection '{collection_name}'\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"\\nProcessing {len(documents)} documents in '{collection_name}'...\")\n",
    "        \n",
    "        # Process documents in batches\n",
    "        for i in range(0, len(documents), batch_size):\n",
    "            batch = documents[i:i + batch_size]\n",
    "            \n",
    "            # Extract text from documents\n",
    "            texts = [extract_text_for_embedding(doc) for doc in batch]\n",
    "            \n",
    "            # Generate embeddings for the batch\n",
    "            embeddings = generate_embeddings_batch(texts)\n",
    "            \n",
    "            if not embeddings or len(embeddings) != len(batch):\n",
    "                print(f\"✗ Embedding generation failed for batch {i//batch_size + 1}\")\n",
    "                continue\n",
    "            \n",
    "            # Update documents with embeddings\n",
    "            for doc, embedding in zip(batch, embeddings):\n",
    "                collection.update_one(\n",
    "                    {\"_id\": doc[\"_id\"]},\n",
    "                    {\"$set\": {\"embeddings\": embedding}}\n",
    "                )\n",
    "            \n",
    "            print(f\"  ✓ Processed batch {i//batch_size + 1}/{(len(documents) + batch_size - 1)//batch_size}\")\n",
    "        \n",
    "        # Verify embeddings were added\n",
    "        docs_with_embeddings = collection.count_documents({\"embeddings\": {\"$exists\": True}})\n",
    "        print(f\"✓ Updated {docs_with_embeddings} documents with embeddings in '{collection_name}'\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error adding embeddings to {collection_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Add embeddings to both collections\n",
    "if MONGODB_URI and test_embeddings:  # Only proceed if embeddings work\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GENERATING AND ADDING EMBEDDINGS TO COLLECTIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    add_embeddings_to_collection(db, \"manuals\", batch_size=5)\n",
    "    add_embeddings_to_collection(db, \"interviews\", batch_size=5)\n",
    "    add_embeddings_to_collection(db, \"workorders\", batch_size=10)\n",
    "else:\n",
    "    print(\"✗ Skipping embedding generation - API not configured or failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4025258",
   "metadata": {},
   "source": [
    "## Section 6: Create Vector Indexes in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31cea92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING VECTOR SEARCH INDEXES\n",
      "============================================================\n",
      "✓ Created vector search index for 'manuals'\n",
      "✓ Created vector search index for 'interviews'\n",
      "✓ Created vector search index for 'workorders'\n"
     ]
    }
   ],
   "source": [
    "def create_vector_search_index(db, collection_name: str, embedding_dim: int = 1024) -> bool:\n",
    "    \"\"\"\n",
    "    Create a vector search index on the embeddings field\n",
    "    \n",
    "    Note: This requires MongoDB Atlas with Atlas Vector Search enabled\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        collection_name: Name of the collection\n",
    "        embedding_dim: Dimension of the embeddings\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        collection = db[collection_name]\n",
    "        \n",
    "        # Vector search index definition for Atlas Vector Search\n",
    "\n",
    "\n",
    "        search_index_model = SearchIndexModel(\n",
    "                                    definition={\n",
    "                                        \"fields\": [\n",
    "                                        {\n",
    "                                            \"type\": \"vector\",\n",
    "                                            \"path\": \"embeddings\",\n",
    "                                            \"numDimensions\": embedding_dim,\n",
    "                                            \"similarity\": \"cosine\"\n",
    "                                        }\n",
    "                                        ]\n",
    "                                    },\n",
    "                                    name=\"vector_index\",\n",
    "                                    type=\"vectorSearch\"\n",
    "                                )\n",
    "\n",
    "\n",
    "        \n",
    "        # Create the index via the collection's create_search_indexes method\n",
    "        # Note: This method requires MongoDB Python driver >= 4.6\n",
    "        try:\n",
    "            # Try using the newer search indexes API\n",
    "            search_indexes = collection.list_search_indexes()\n",
    "            existing_indexes = [idx.get('name') for idx in search_indexes]\n",
    "            for index in existing_indexes:\n",
    "                print(index)\n",
    "            \n",
    "            if 'vector_index' not in existing_indexes:\n",
    "                collection.create_search_index(model=search_index_model)\n",
    "                print(f\"✓ Created vector search index for '{collection_name}'\")\n",
    "            else:\n",
    "                print(f\"✓ Vector search index already exists for '{collection_name}'\")\n",
    "                \n",
    "        except AttributeError:\n",
    "            # Fallback for older driver versions\n",
    "            print(f\"⚠ Vector search index creation requires MongoDB Atlas with Vector Search enabled\")\n",
    "            print(f\"  Manually create the index in MongoDB Atlas UI with this definition:\")\n",
    "            print(f\"  {json.dumps(index_definition, indent=2)}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Note: {e}\")\n",
    "        print(f\"  Vector indexes should be created in MongoDB Atlas UI\")\n",
    "        return False\n",
    "\n",
    "# Create vector indexes for both collections\n",
    "if MONGODB_URI and test_embeddings:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CREATING VECTOR SEARCH INDEXES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Use embedding dimension from test\n",
    "    embedding_dim = len(test_embeddings[0]) if test_embeddings else 1024\n",
    "    \n",
    "    create_vector_search_index(db, \"manuals\", embedding_dim)\n",
    "    create_vector_search_index(db, \"interviews\", embedding_dim)\n",
    "    create_vector_search_index(db, \"workorders\", embedding_dim)\n",
    "else:\n",
    "    print(\"✗ Skipping index creation - prerequisites not met\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8e2cf",
   "metadata": {},
   "source": [
    "## Section 7: Implement RAG Solution with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a75e335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAG system initialized successfully\n"
     ]
    }
   ],
   "source": [
    "def vector_search_mongodb(db, collection_name: str, query_vector: List[float], num_results: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform vector similarity search on MongoDB collection\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        collection_name: Name of the collection to search\n",
    "        query_vector: Query embedding vector\n",
    "        num_results: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of matching documents with similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        collection = db[collection_name]\n",
    "        \n",
    "        # Use aggregation pipeline with vector search\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$vectorSearch\": {\n",
    "                    \"index\": \"vector_index\",\n",
    "                    'queryVector': query_vector,\n",
    "                    'numCandidates': 10, \n",
    "                    'limit': num_results\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"'score\": {\"$meta\": \"vectorSearchScore\"},\n",
    "                    \"document\": \"$$ROOT\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$limit\": num_results\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Try standard vector search first\n",
    "        try:\n",
    "            results = list(collection.aggregate(pipeline))\n",
    "            return results\n",
    "        except:\n",
    "            # Fallback to simpler approach if aggregation fails\n",
    "            # This works with documents that have embeddings field\n",
    "            results = []\n",
    "            documents = list(collection.find({\"embeddings\": {\"$exists\": True}}))\n",
    "            \n",
    "            if not documents:\n",
    "                return []\n",
    "            \n",
    "            # Calculate similarity scores using cosine similarity\n",
    "            import numpy as np\n",
    "            query_vec = np.array(query_vector)\n",
    "            \n",
    "            for doc in documents:\n",
    "                if 'embeddings' in doc:\n",
    "                    doc_vec = np.array(doc['embeddings'])\n",
    "                    # Cosine similarity\n",
    "                    similarity = np.dot(query_vec, doc_vec) / (np.linalg.norm(query_vec) * np.linalg.norm(doc_vec))\n",
    "                    results.append({\n",
    "                        'similarityScore': float(similarity),\n",
    "                        'document': doc\n",
    "                    })\n",
    "            \n",
    "            # Sort by similarity score and return top results\n",
    "            results.sort(key=lambda x: x['similarityScore'], reverse=True)\n",
    "            return results[:num_results]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error performing vector search: {e}\")\n",
    "        return []\n",
    "\n",
    "def retrieve_context(db, query: str, num_results: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant context from both collections using vector search\n",
    "    \n",
    "    Args:\n",
    "        db: MongoDB database object\n",
    "        query: User query\n",
    "        num_results: Number of results per collection\n",
    "        \n",
    "    Returns:\n",
    "        Formatted context string for RAG\n",
    "    \"\"\"\n",
    "    # Generate query embedding\n",
    "    query_embedding = generate_embeddings_batch([query])\n",
    "    \n",
    "    if not query_embedding:\n",
    "        return \"No context available\"\n",
    "    \n",
    "    query_vector = query_embedding[0]\n",
    "    \n",
    "    # Search both collections\n",
    "    manual_results = vector_search_mongodb(db, \"manuals\", query_vector, num_results)\n",
    "    interview_results = vector_search_mongodb(db, \"interviews\", query_vector, num_results)\n",
    "    workorder_results = vector_search_mongodb(db, \"workorders\", query_vector, num_results)\n",
    "\n",
    "    # Format context\n",
    "    context = \"Retrieved Context:\\n\\n\"\n",
    "    \n",
    "    if manual_results:\n",
    "        context += \"=== From Manuals ===\\n\"\n",
    "        for i, result in enumerate(manual_results, 1):\n",
    "            doc = result.get('document', result)\n",
    "            score = result.get('similarityScore', 0)\n",
    "            text = extract_text_for_embedding(doc)[:500]  # Limit text length\n",
    "            context += f\"{i}. (Score: {score:.2f}) {text}...\\n\\n\"\n",
    "    \n",
    "    if interview_results:\n",
    "        context += \"=== From Interviews ===\\n\"\n",
    "        for i, result in enumerate(interview_results, 1):\n",
    "            doc = result.get('document', result)\n",
    "            score = result.get('similarityScore', 0)\n",
    "            text = extract_text_for_embedding(doc)[:500]  # Limit text length\n",
    "            context += f\"{i}. (Score: {score:.2f}) {text}...\\n\\n\"\n",
    "\n",
    "    if workorder_results:\n",
    "        context += \"=== From Work Orders ===\\n\"\n",
    "        for i, result in enumerate(workorder_results, 1):\n",
    "            doc = result.get('document', result)\n",
    "            score = result.get('similarityScore', 0)\n",
    "            text = extract_text_for_embedding(doc)[:500]  # Limit text length\n",
    "            context += f\"{i}. (Score: {score:.2f}) {text}...\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "# Initialize RAG system\n",
    "class MongoDBOpenAIRAG:\n",
    "    \"\"\"RAG system using MongoDB Atlas and OpenAI\"\"\"\n",
    "    \n",
    "    def __init__(self, db, model: str = \"gpt-3.5-turbo\", temperature: float = 0.7):\n",
    "        self.db = db\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def answer_question(self, query: str, num_context_docs: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Answer a question using RAG approach\n",
    "        \n",
    "        Args:\n",
    "            query: User question\n",
    "            num_context_docs: Number of context documents to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            Dict with answer, context, and sources\n",
    "        \"\"\"\n",
    "        # Retrieve context\n",
    "        context = retrieve_context(self.db, query, num_context_docs)\n",
    "        \n",
    "        # Create prompt for OpenAI\n",
    "        system_prompt = \"\"\"You are a helpful assistant answering questions about maintenance systems and procedures.\n",
    "Use the provided context to answer the question accurately. If the context doesn't contain relevant information, say so.\n",
    "Always cite your sources from the context.\"\"\"\n",
    "        \n",
    "        user_message = f\"\"\"Context Information:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Please provide a helpful answer based on the context above.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Call OpenAI API\n",
    "            response = llm_client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_message}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=500\n",
    "            )\n",
    "\n",
    "            answer = response.choices[0].message.content\n",
    "\n",
    "            return {\n",
    "                'success': True,\n",
    "                'query': query,\n",
    "                'answer': answer,\n",
    "                'context': context,\n",
    "                'model': self.model\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'query': query,\n",
    "                'error': str(e),\n",
    "                'context': context\n",
    "            }\n",
    "\n",
    "# Initialize RAG system\n",
    "if MONGODB_URI and LLM_API_KEY:\n",
    "    rag_system = MongoDBOpenAIRAG(db)\n",
    "    print(\"✓ RAG system initialized successfully\")\n",
    "else:\n",
    "    print(\"✗ RAG system initialization failed - missing API keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73cfa0",
   "metadata": {},
   "source": [
    "## Section 8: Query and Retrieve Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb75ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RAG SYSTEM DEMONSTRATION\n",
      "======================================================================\n",
      "\n",
      "Running example queries...\n",
      "\n",
      "\n",
      "--- Query 1 ---\n",
      "✓ Generated 1 embeddings using voyage-3-large\n",
      "\n",
      "======================================================================\n",
      "QUERY: What are the maintenance procedures for critical equipment?\n",
      "======================================================================\n",
      "\n",
      "ANSWER:\n",
      "Based on the information provided in the context, the maintenance procedures for critical equipment should include the following steps:\n",
      "\n",
      "1. Weekly lubrication of bearings.\n",
      "2. Weekly inspection of coolant lines for blockages or low levels.\n",
      "3. Monthly full system alignment check.\n",
      "4. Bi-monthly replacement of wear-prone tools.\n",
      "5. Visual inspection of impeller condition for wear or degradation in case of fault code E12 (High Temperature).\n",
      "6. Checking coolant system for blockages or low levels in case of high-temp alerts.\n",
      "7. Verifying proper functioning of the lubrication system.\n",
      "8. Monitoring vibration levels and investigating any alerts that indicate bearing misalignment.\n",
      "\n",
      "These maintenance procedures are crucial for preventing issues such as high temperatures, tool wear, coolant blockages, and bearing overheating in critical equipment.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "CONTEXT SOURCES:\n",
      "Retrieved Context:\n",
      "\n",
      "=== From Manuals ===\n",
      "1. (Score: 0.71) Maintenance Schedule:\n",
      "- Lubricate bearings: Weekly\n",
      "- Inspect coolant lines: Weekly\n",
      "- Full system alignment check: Monthly\n",
      "- Replace wear-prone tools: Bi-monthly...\n",
      "\n",
      "2. (Score: 0.67) Fault Code: E12 – High Temperature\n",
      "Possible Causes:\n",
      "- Tool wear or degradation\n",
      "- Blocked coolant channels\n",
      "- Inadequate lubrication\n",
      "Recommended Actions:\n",
      "1. Inspect cutting tool for wear; replace if needed.\n",
      "2. Check coolant system for blockages or low levels.\n",
      "3. Verify lubrication system is functioning....\n",
      "\n",
      "=== From Interviews ===\n",
      "1. (Score: 0.70) We trained the new hires to always check the impeller condition manually if they see E13. It’s not enough to rely on sensors — visual inspection has caught small cracks or buildup that caused minor imbalances. It's subtle, but enough to trigger an alert....\n",
      "\n",
      "2. (Score: 0.69) There was a period last quarter when we got repeated high-temp alerts on M1. We traced it back to an intermittent coolant blockage that wouldn’t show up during routine checks. The flexible tubing was kinking under pressure at high RPMs. We had to add a bracket to keep it stable....\n",
      "\n",
      "=== From Work Orders ===\n",
      "1. (Score: 0.74) Lubrication System Inspection Lubrication pump running intermittently. Caused overheating of bearings....\n",
      "\n",
      "2. (Score: 0.73) Vibration Alert Investigation Vibration exceeded 1.9 mm/s. Bearing misalignment suspected....\n",
      "\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- Query 2 ---\n",
      "✓ Generated 1 embeddings using voyage-3-large\n",
      "\n",
      "======================================================================\n",
      "QUERY: How do you troubleshoot sensor failures?\n",
      "======================================================================\n",
      "\n",
      "ANSWER:\n",
      "The context provided does not offer specific information on troubleshooting sensor failures.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "CONTEXT SOURCES:\n",
      "Retrieved Context:\n",
      "\n",
      "=== From Manuals ===\n",
      "1. (Score: 0.73) Fault Code: E12 – High Temperature\n",
      "Possible Causes:\n",
      "- Tool wear or degradation\n",
      "- Blocked coolant channels\n",
      "- Inadequate lubrication\n",
      "Recommended Actions:\n",
      "1. Inspect cutting tool for wear; replace if needed.\n",
      "2. Check coolant system for blockages or low levels.\n",
      "3. Verify lubrication system is functioning....\n",
      "\n",
      "2. (Score: 0.72) Fault Code: E13 – High Vibration\n",
      "Possible Causes:\n",
      "- Bearing misalignment\n",
      "- Loose mechanical fittings\n",
      "- Imbalance in rotating assembly\n",
      "Recommended Actions:\n",
      "1. Inspect and align shaft bearings.\n",
      "2. Tighten all mounting bolts and fixtures.\n",
      "3. Check for wear on impeller and balance as needed....\n",
      "\n",
      "=== From Interviews ===\n",
      "1. (Score: 0.73) We trained the new hires to always check the impeller condition manually if they see E13. It’s not enough to rely on sensors — visual inspection has caught small cracks or buildup that caused minor imbalances. It's subtle, but enough to trigger an alert....\n",
      "\n",
      "2. (Score: 0.72) When you get a high temperature alert on M1, nine times out of ten it’s due to tool wear, especially if it hasn’t been replaced in the last month. Even if the coolant looks fine, a dull tool can generate a lot of heat. It's not always logged properly in the system, so the best bet is to inspect the tool first before doing anything drastic....\n",
      "\n",
      "=== From Work Orders ===\n",
      "1. (Score: 0.77) Vibration Sensor False Trigger Review Alert only occurred during startup phase. No mechanical faults found....\n",
      "\n",
      "2. (Score: 0.77) Sensor Calibration Routine Vibration sensor drifted over time. Readings were 0.2 mm/s too high....\n",
      "\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- Query 3 ---\n",
      "✓ Generated 1 embeddings using voyage-3-large\n",
      "\n",
      "======================================================================\n",
      "QUERY: What is the recommended maintenance schedule?\n",
      "======================================================================\n",
      "\n",
      "ANSWER:\n",
      "Based on the information provided in the context, the recommended maintenance schedule includes the following tasks:\n",
      "- Lubricate bearings weekly\n",
      "- Inspect coolant lines weekly\n",
      "- Perform a full system alignment check monthly\n",
      "- Replace wear-prone tools bi-monthly\n",
      "\n",
      "These maintenance tasks are crucial for ensuring the proper functioning and longevity of the system components. Regular lubrication, inspection of coolant lines, alignment checks, and timely replacement of wear-prone tools can help prevent issues such as overheating due to bearing problems, coolant blockages, and high temperatures caused by tool wear.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "CONTEXT SOURCES:\n",
      "Retrieved Context:\n",
      "\n",
      "=== From Manuals ===\n",
      "1. (Score: 0.70) Maintenance Schedule:\n",
      "- Lubricate bearings: Weekly\n",
      "- Inspect coolant lines: Weekly\n",
      "- Full system alignment check: Monthly\n",
      "- Replace wear-prone tools: Bi-monthly...\n",
      "\n",
      "2. (Score: 0.67) For further support, contact TechFlow Service at support@techflow.com or +1-800-TECH-123....\n",
      "\n",
      "=== From Interviews ===\n",
      "1. (Score: 0.70) There was a period last quarter when we got repeated high-temp alerts on M1. We traced it back to an intermittent coolant blockage that wouldn’t show up during routine checks. The flexible tubing was kinking under pressure at high RPMs. We had to add a bracket to keep it stable....\n",
      "\n",
      "2. (Score: 0.67) When you get a high temperature alert on M1, nine times out of ten it’s due to tool wear, especially if it hasn’t been replaced in the last month. Even if the coolant looks fine, a dull tool can generate a lot of heat. It's not always logged properly in the system, so the best bet is to inspect the tool first before doing anything drastic....\n",
      "\n",
      "=== From Work Orders ===\n",
      "1. (Score: 0.74) Lubrication System Inspection Lubrication pump running intermittently. Caused overheating of bearings....\n",
      "\n",
      "2. (Score: 0.71) Coolant Blockage Troubleshooting Repeated high-temp alerts. Tubing found kinked under high RPM load....\n",
      "\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_rag_response(response: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Format RAG response for display\n",
    "    \n",
    "    Args:\n",
    "        response: Response dictionary from RAG system\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string for display\n",
    "    \"\"\"\n",
    "    output = \"\\n\" + \"=\" * 70 + \"\\n\"\n",
    "    output += f\"QUERY: {response.get('query', 'N/A')}\\n\"\n",
    "    output += \"=\" * 70 + \"\\n\\n\"\n",
    "    \n",
    "    if response.get('success'):\n",
    "        output += f\"ANSWER:\\n{response.get('answer', 'No answer generated')}\\n\\n\"\n",
    "        output += \"-\" * 70 + \"\\n\"\n",
    "        output += f\"CONTEXT SOURCES:\\n{response.get('context', 'No context retrieved')}\\n\"\n",
    "    else:\n",
    "        output += f\"ERROR: {response.get('error', 'Unknown error')}\\n\"\n",
    "        output += f\"RETRIEVED CONTEXT:\\n{response.get('context', 'No context')}\\n\"\n",
    "    \n",
    "    output += \"=\" * 70 + \"\\n\"\n",
    "    return output\n",
    "\n",
    "# Example queries to test the RAG system\n",
    "example_queries = [\n",
    "    \"What are the maintenance procedures for critical equipment?\",\n",
    "    \"How do you troubleshoot sensor failures?\",\n",
    "    \"What is the recommended maintenance schedule?\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RAG SYSTEM DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'rag_system' in locals() and MONGODB_URI:\n",
    "    print(\"\\nRunning example queries...\\n\")\n",
    "    \n",
    "    for i, query in enumerate(example_queries, 1):\n",
    "        print(f\"\\n--- Query {i} ---\")\n",
    "        response = rag_system.answer_question(query, num_context_docs=2)\n",
    "        formatted = format_rag_response(response)\n",
    "        print(formatted)\n",
    "        \n",
    "        # Add a small delay between API calls to avoid rate limiting\n",
    "        import time\n",
    "        if i < len(example_queries):\n",
    "            time.sleep(2)\n",
    "else:\n",
    "    print(\"\\n✗ RAG system not available for querying\")\n",
    "    print(\"  Ensure MONGODB_URI and OPENAI_API_KEY are configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e4a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ RAG system not initialized\n",
      "\n",
      "======================================================================\n",
      "NOTEBOOK COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Summary of RAG Pipeline:\n",
      "✓ Data loaded from data folder\n",
      "✓ Data ingested into MongoDB Atlas\n",
      "✓ Embeddings generated using Voyage AI 3\n",
      "✓ Collections updated with embeddings\n",
      "✓ Vector indexes created\n",
      "✓ RAG system implemented with OpenAI\n",
      "\n",
      "To use the interactive interface, uncomment and run the interactive_rag_query() cell.\n",
      "\n",
      "To ask custom questions, use:\n",
      "  result = rag_system.answer_question(\"Your question here\")\n",
      "  print(result)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interactive query interface\n",
    "def interactive_rag_query():\n",
    "    \"\"\"\n",
    "    Interactive interface for querying the RAG system\n",
    "    \n",
    "    Usage:\n",
    "        Call this function and enter your questions when prompted.\n",
    "        Type 'exit' to quit.\n",
    "    \"\"\"\n",
    "    if 'rag_system' not in locals():\n",
    "        print(\"✗ RAG system not initialized\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"INTERACTIVE RAG QUERY INTERFACE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Enter your questions about the maintenance data.\")\n",
    "    print(\"Type 'exit' to quit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"Your question: \").strip()\n",
    "            \n",
    "            if query.lower() == 'exit':\n",
    "                print(\"Exiting RAG system...\")\n",
    "                break\n",
    "            \n",
    "            if not query:\n",
    "                print(\"Please enter a question.\\n\")\n",
    "                continue\n",
    "            \n",
    "            print(\"\\nProcessing your query...\\n\")\n",
    "            response = rag_system.answer_question(query, num_context_docs=3)\n",
    "            formatted = format_rag_response(response)\n",
    "            print(formatted)\n",
    "            \n",
    "            # Add delay to avoid rate limiting\n",
    "            import time\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nExiting RAG system...\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query: {e}\\n\")\n",
    "\n",
    "# Uncomment the line below to run the interactive interface\n",
    "# interactive_rag_query()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NOTEBOOK COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Summary of RAG Pipeline:\n",
    "✓ Data loaded from data folder\n",
    "✓ Data ingested into MongoDB Atlas\n",
    "✓ Embeddings generated using Voyage AI 3\n",
    "✓ Collections updated with embeddings\n",
    "✓ Vector indexes created\n",
    "✓ RAG system implemented with OpenAI\n",
    "\n",
    "To use the interactive interface, uncomment and run the interactive_rag_query() cell.\n",
    "\n",
    "To ask custom questions, use:\n",
    "  result = rag_system.answer_question(\"Your question here\")\n",
    "  print(result)\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
